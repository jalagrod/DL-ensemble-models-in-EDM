{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'WeightedEnsemble_L2',\n",
       " 'model_type': 'WeightedEnsembleModel',\n",
       " 'model_params': {'use_orig_features': False,\n",
       "  'max_base_models': 25,\n",
       "  'max_base_models_per_type': 5,\n",
       "  'save_bag_folds': True},\n",
       " 'model_layers': 'None',\n",
       " 'base_models': [{'model_name': 'NeuralNetTorch_r79_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'model_params': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'model_layers': 'None',\n",
       "   'base_models': []},\n",
       "  {'model_name': 'NeuralNetFastAI_r102_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'model_params': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'model_layers': 'None',\n",
       "   'base_models': []},\n",
       "  {'model_name': 'NeuralNetFastAI_r143_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'model_params': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'model_layers': 'None',\n",
       "   'base_models': []},\n",
       "  {'model_name': 'NeuralNetTorch_r41_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'model_params': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'model_layers': 'None',\n",
       "   'base_models': []},\n",
       "  {'model_name': 'NeuralNetFastAI_r37_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'model_params': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'model_layers': 'None',\n",
       "   'base_models': []},\n",
       "  {'model_name': 'NeuralNetTorch_r143_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'model_params': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'model_layers': 'None',\n",
       "   'base_models': []},\n",
       "  {'model_name': 'NeuralNetFastAI_r111_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'model_params': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'model_layers': 'None',\n",
       "   'base_models': []}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import os\n",
    "\n",
    "predictor_path = r\"\"\n",
    "\n",
    "predictor = TabularPredictor.load(predictor_path)\n",
    "\n",
    "best_model_name = predictor.model_best\n",
    "best_model = predictor._trainer.load_model(best_model_name)\n",
    "\n",
    "def get_model_info(model):\n",
    "    model_info = {\n",
    "        'model_name': model.name,\n",
    "        'model_type': model.__class__.__name__,\n",
    "        'model_params': model.params,\n",
    "        'model_layers': str(model.model) if hasattr(model, 'model') else 'N/A',\n",
    "        'base_models': []\n",
    "    }\n",
    "    \n",
    "    if hasattr(model, 'base_model_names'):\n",
    "        for base_model_name in model.base_model_names:\n",
    "            base_model = predictor._trainer.load_model(base_model_name)\n",
    "            model_info['base_models'].append(get_model_info(base_model))\n",
    "    \n",
    "    return model_info\n",
    "\n",
    "best_model_info = get_model_info(best_model)\n",
    "\n",
    "best_model_info\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
