{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda create -n ag python=3.10\n",
    "#!conda activate ag\n",
    "#!conda install -c conda-forge mamba\n",
    "#!mamba install -c conda-forge -c pytorch -c nvidia autogluon \"pytorch=*=*cuda*\"\n",
    "#!mamba install -c conda-forge \"ray-tune >=2.6.3,<2.7\" \"ray-default >=2.6.3,<2.7\"  # install ray for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting autogluon\n",
      "  Using cached autogluon-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.2 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.features==1.2 (from autogluon)\n",
      "  Using cached autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting autogluon.multimodal==1.2 (from autogluon)\n",
      "  Using cached autogluon.multimodal-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.timeseries==1.2 (from autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached autogluon.timeseries-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.16,>=1.5.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn<1.5.3,>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.2)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.2.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.2)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.66.4)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.32.2)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.8.4)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading boto3-1.36.21-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached ray-2.39.0-cp312-cp312-win_amd64.whl.metadata (18 kB)\n",
      "Collecting pyarrow>=15.0.0 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: Pillow<12,>=10.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (10.3.0)\n",
      "Requirement already satisfied: torch<2.6,>=2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (2.3.1+cu121)\n",
      "Collecting lightning<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting transformers<5,>=4.38.0 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting accelerate<1.0,>=0.34.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: jsonschema<4.22,>=4.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (4.19.2)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: torchvision<0.21.0,>=0.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.18.1+cu121)\n",
      "Requirement already satisfied: scikit-image<0.25.0,>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.23.2)\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (1.3)\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: nltk<3.9,>=3.4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (3.8.1)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.7.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (3.1.4)\n",
      "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached nvidia_ml_py3-7.352.0-py3-none-any.whl\n",
      "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting spacy<3.8 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached spacy-3.7.5-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting lightgbm<4.6,>=4.0 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Collecting einops<0.9,>=0.7 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting xgboost<2.2,>=1.6 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached fastai-2.7.18-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting huggingface-hub[torch] (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.2)\n",
      "Collecting pytorch-lightning (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached gluonts-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting statsforecast<1.8,>=1.7.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached statsforecast-1.7.8-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting mlforecast==0.13.4 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached mlforecast-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting utilsforecast<0.2.5,>=0.2.3 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached utilsforecast-0.2.4-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting coreforecast==0.0.12 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached coreforecast-0.0.12-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (5.9.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.2.1)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2024.3.1)\n",
      "Requirement already satisfied: numba in c:\\programdata\\anaconda3\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.59.1)\n",
      "Collecting optuna (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (23.2)\n",
      "Collecting window-ops (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (6.0.1)\n",
      "Collecting safetensors>=0.4.3 (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting botocore<1.37.0,>=1.36.21 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading botocore-1.36.21-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.0.1)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (1.16.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: dill in c:\\programdata\\anaconda3\\lib\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon) (0.3.8)\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pip in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (24.0)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastcore-1.7.29-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.5.3)\n",
      "Requirement already satisfied: toolz~=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.11.0)\n",
      "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.2->autogluon) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.10.6)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.9.0.post0)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (2023.10.3)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.4.6)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (13.3.5)\n",
      "Requirement already satisfied: tabulate in c:\\programdata\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2023.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.13.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.0.3)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.20.3)\n",
      "Requirement already satisfied: aiosignal in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: frozenlist in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.4.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.9.5)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached py_spy-0.4.0-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.14.1)\n",
      "Requirement already satisfied: smart-open in c:\\programdata\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.2.1)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.7.4)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2023.4.12)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached thinc-8.2.5-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (70.3.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.14.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.0.3)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.12)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (2021.4.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5,>=4.38.0->transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.9.3)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (4.12.3)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\programdata\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\programdata\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (2021.11.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.42.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.14.6)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.13.2->statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.5.6)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached blis-0.7.11-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.15.1)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.10.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\programdata\\anaconda3\\lib\\site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (305.1)\n",
      "Collecting alembic>=1.5.0 (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.0.30)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (8.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.3.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (2.5)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.4)\n",
      "Collecting filelock (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached oss2-2.17.0.tar.gz (259 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting packaging (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (1.7.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.4.8)\n",
      "Using cached autogluon-1.2-py3-none-any.whl (9.6 kB)\n",
      "Using cached autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
      "Using cached autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
      "Using cached autogluon.multimodal-1.2-py3-none-any.whl (429 kB)\n",
      "Using cached autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
      "Using cached autogluon.timeseries-1.2-py3-none-any.whl (174 kB)\n",
      "Using cached autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
      "Using cached coreforecast-0.0.12-py3-none-win_amd64.whl (101 kB)\n",
      "Using cached mlforecast-0.13.4-py3-none-any.whl (70 kB)\n",
      "Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Downloading boto3-1.36.21-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.2/139.2 kB 4.2 MB/s eta 0:00:00\n",
      "Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl (101.7 MB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.4/64.4 kB 3.4 MB/s eta 0:00:00\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Using cached fastai-2.7.18-py3-none-any.whl (234 kB)\n",
      "Using cached fugue-0.9.1-py3-none-any.whl (278 kB)\n",
      "Using cached gluonts-0.16.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "Using cached lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
      "Using cached nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "Using cached omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "Using cached openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 7.7 MB/s eta 0:00:00\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/25.2 MB 12.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.3/25.2 MB 13.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.3/25.2 MB 15.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.2/25.2 MB 18.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.2/25.2 MB 18.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.2/25.2 MB 22.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 8.9/25.2 MB 27.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.2/25.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.7/25.2 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.7/25.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.9/25.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 46.7 MB/s eta 0:00:00\n",
      "Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Using cached pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
      "Using cached ray-2.39.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "Using cached spacy-3.7.5-cp312-cp312-win_amd64.whl (11.7 MB)\n",
      "Using cached statsforecast-1.7.8-cp312-cp312-win_amd64.whl (255 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.0/5.5 MB 43.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 58.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 49.9 MB/s eta 0:00:00\n",
      "Using cached timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "Using cached torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 3.4/9.7 MB 72.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.0/9.7 MB 74.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 77.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 61.5 MB/s eta 0:00:00\n",
      "Using cached utilsforecast-0.2.4-py3-none-any.whl (40 kB)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.8/124.9 MB 91.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 5.0/124.9 MB 64.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 8.2/124.9 MB 65.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 11.3/124.9 MB 65.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 13.7/124.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 15.6/124.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 17.7/124.9 MB 54.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 19.8/124.9 MB 46.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 22.1/124.9 MB 46.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 24.5/124.9 MB 46.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 26.9/124.9 MB 46.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 29.2/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 31.6/124.9 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 33.9/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 36.3/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 38.7/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.3/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 43.8/124.9 MB 54.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 45.7/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 48.2/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 50.7/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 53.3/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 55.8/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 58.5/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 61.2/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 63.9/124.9 MB 54.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 66.3/124.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 68.3/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 70.3/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 72.3/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 73.7/124.9 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 73.7/124.9 MB 38.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 73.8/124.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 74.4/124.9 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 76.5/124.9 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 78.6/124.9 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 80.7/124.9 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 82.8/124.9 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 82.9/124.9 MB 26.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 83.4/124.9 MB 23.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 84.0/124.9 MB 26.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 84.2/124.9 MB 26.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 85.1/124.9 MB 25.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 86.7/124.9 MB 24.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 88.3/124.9 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 89.9/124.9 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 91.4/124.9 MB 22.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 94.8/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 96.4/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 98.1/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 99.9/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 101.7/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 103.2/124.9 MB 36.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 104.7/124.9 MB 36.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 106.5/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 108.0/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 108.9/124.9 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 110.8/124.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 112.8/124.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 114.9/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 116.7/124.9 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 118.5/124.9 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 120.6/124.9 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  122.6/124.9 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.6/124.9 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.9/124.9 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.9/124.9 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.9/124.9 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 27.3 MB/s eta 0:00:00\n",
      "Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached adagio-0.2.6-py3-none-any.whl (19 kB)\n",
      "Downloading botocore-1.36.21-py3-none-any.whl (13.4 MB)\n",
      "   ---------------------------------------- 0.0/13.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/13.4 MB 57.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.9/13.4 MB 50.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/13.4 MB 48.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.2/13.4 MB 47.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.3/13.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.5/13.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.4/13.4 MB 40.9 MB/s eta 0:00:00\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
      "   ---------------------------------------- 0.0/484.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 484.9/484.9 kB 31.6 MB/s eta 0:00:00\n",
      "Downloading fastcore-1.7.29-py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 0.0/84.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 84.2/84.2 kB 4.6 MB/s eta 0:00:00\n",
      "Using cached fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Using cached fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.7/4.3 MB 53.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.0/4.3 MB 50.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 38.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "   ---------------------------------------- 0.0/464.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 464.1/464.1 kB 14.2 MB/s eta 0:00:00\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Using cached preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "Using cached py_spy-0.4.0-py2.py3-none-win_amd64.whl (1.8 MB)\n",
      "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 0.0/84.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 84.2/84.2 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "   ---------------------------------------- 0.0/303.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 303.8/303.8 kB ? eta 0:00:00\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 632.6/632.6 kB 41.5 MB/s eta 0:00:00\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Using cached thinc-8.2.5-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached triad-0.9.8-py3-none-any.whl (62 kB)\n",
      "Using cached typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.1/4.3 MB 68.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 55.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 45.7 MB/s eta 0:00:00\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Using cached model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Using cached opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Using cached opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "   ---------------------------------------- 0.0/383.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 383.6/383.6 kB 24.9 MB/s eta 0:00:00\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "   ---------------------------------------- 0.0/203.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 203.0/203.0 kB 12.9 MB/s eta 0:00:00\n",
      "Using cached window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 233.6/233.6 kB 14.9 MB/s eta 0:00:00\n",
      "Using cached blis-0.7.11-cp312-cp312-win_amd64.whl (6.6 MB)\n",
      "Using cached cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 160.1/160.1 kB 9.4 MB/s eta 0:00:00\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Using cached openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
      "Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Using cached pycryptodome-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "   ---------------------------------------- 0.0/210.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 210.8/210.8 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/165.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 165.0/165.0 kB ? eta 0:00:00\n",
      "Using cached marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.5 MB/s eta 0:00:00\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: sentencepiece, py4j, py-spy, opencensus-context, nvidia-ml-py3, distlib, cymem, antlr4-python3-runtime, xxhash, wasabi, virtualenv, threadpoolctl, tensorboardX, tensorboard-data-server, spacy-loggers, spacy-legacy, shellingham, safetensors, rsa, pytesseract, pycryptodome, pyarrow, proto-plus, pdf2image, orjson, ordered-set, openxlab, omegaconf, murmurhash, multiprocess, marisa-trie, Mako, lightning-utilities, grpcio, graphviz, googleapis-common-protos, future, fs, fastprogress, fastcore, einops, coreforecast, colorlog, colorful, cloudpathlib, catalogue, blis, absl-py, xgboost, window-ops, tensorboard, srsly, preshed, model-index, lightgbm, language-data, hyperopt, huggingface-hub, google-auth, fastdownload, botocore, alembic, utilsforecast, typer, triad, torchmetrics, tokenizers, seqeval, s3transfer, pytorch-metric-learning, optuna, opendatalab, langcodes, google-api-core, gluonts, gdown, confection, catboost, aiohttp-cors, accelerate, weasel, transformers, timm, thinc, ray, pytorch-lightning, openmim, opencensus, nlpaug, mlforecast, datasets, boto3, adagio, spacy, lightning, fugue, evaluate, autogluon.common, statsforecast, fastai, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
      "Successfully installed Mako-1.3.9 absl-py-2.1.0 accelerate-0.34.2 adagio-0.2.6 aiohttp-cors-0.7.0 alembic-1.14.1 antlr4-python3-runtime-4.9.3 autogluon-1.2 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.multimodal-1.2 autogluon.tabular-1.2 autogluon.timeseries-1.2 blis-0.7.11 boto3-1.36.21 botocore-1.36.21 catalogue-2.0.10 catboost-1.2.7 cloudpathlib-0.20.0 colorful-0.5.6 colorlog-6.9.0 confection-0.1.5 coreforecast-0.0.12 cymem-2.0.11 datasets-3.3.0 distlib-0.3.9 einops-0.8.1 evaluate-0.4.3 fastai-2.7.18 fastcore-1.7.29 fastdownload-0.0.7 fastprogress-1.0.3 fs-2.4.16 fugue-0.9.1 future-1.0.0 gdown-5.2.0 gluonts-0.16.0 google-api-core-2.24.1 google-auth-2.38.0 googleapis-common-protos-1.67.0 graphviz-0.20.3 grpcio-1.70.0 huggingface-hub-0.28.1 hyperopt-0.2.7 langcodes-3.5.0 language-data-1.3.0 lightgbm-4.5.0 lightning-2.5.0.post0 lightning-utilities-0.12.0 marisa-trie-1.2.1 mlforecast-0.13.4 model-index-0.1.11 multiprocess-0.70.16 murmurhash-1.0.12 nlpaug-1.1.11 nvidia-ml-py3-7.352.0 omegaconf-2.2.3 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.2.1 ordered-set-4.1.0 orjson-3.10.15 pdf2image-1.17.0 preshed-3.0.9 proto-plus-1.26.0 py-spy-0.4.0 py4j-0.10.9.9 pyarrow-19.0.0 pycryptodome-3.21.0 pytesseract-0.3.10 pytorch-lightning-2.5.0.post0 pytorch-metric-learning-2.3.0 ray-2.39.0 rsa-4.9 s3transfer-0.11.2 safetensors-0.5.2 sentencepiece-0.2.0 seqeval-1.2.2 shellingham-1.5.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 statsforecast-1.7.8 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 thinc-8.2.5 threadpoolctl-3.5.0 timm-1.0.3 tokenizers-0.21.0 torchmetrics-1.2.1 transformers-4.48.3 triad-0.9.8 typer-0.15.1 utilsforecast-0.2.4 virtualenv-20.29.2 wasabi-1.1.3 weasel-0.4.1 window-ops-0.0.15 xgboost-2.1.4 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script virtualenv.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pytesseract.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openxlab.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mako-render.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts futurize.exe and pasteurize.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts py2pyi.exe and replace_wildcards.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mi.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script hyperopt-mongo-worker.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script alembic.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script typer.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script optuna.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script odl.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script gdown.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script weasel.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts ray.exe, rllib.exe, serve.exe and tune.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mim.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script spacy.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fabric.exe and lightning.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script evaluate-cli.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script configure_accelerate.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.36.21 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# %pip install autogluon\n",
    "#!pip install --upgrade numpy pandas scipy\n",
    "#!pip install numpy==1.26.4\n",
    "#!pip install pyJoules\n",
    "#!pip install mxnet-cu110\n",
    "#!pip install jedi\n",
    "#!pip install setuptools\n",
    "#!pip install scikit-learn==1.3.0\n",
    "#!pip install pandas==2.0.0\n",
    "#!pip install fsspec==2023.1.0\n",
    "#!pip install torch==2.0.1+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "#cls\n",
    "# !pip install cudatoolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "print(torch.cuda.device_count())  # Should be > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.4\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          32\n",
      "Memory Avail:       50.21 GB / 63.94 GB (78.5%)\n",
      "Disk Space Avail:   128.36 GB / 464.91 GB (27.6%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=10, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-02-16 17:19:26,885\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"GPU_1_XAPI_DL_VALIDATION_kfold\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Beginning AutoGluon training ... Time limit = 896s\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m AutoGluon will save models to \"GPU_1_XAPI_DL_VALIDATION_kfold\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Train Data Rows:    426\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Train Data Columns: 16\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Label Column:       Class\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Problem Type:       multiclass\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Train Data Class Count: 3\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tAvailable Memory:                    50447.66 MB\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\t('int', [])    :  4 | ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\t('object', []) : 12 | ['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', ...]\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\t('category', [])  : 6 | ['NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', 'SectionID', ...]\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\t('int', [])       : 4 | ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t\t('int', ['bool']) : 6 | ['gender', 'Semester', 'Relation', 'ParentAnsweringSurvey', 'ParentschoolSatisfaction', ...]\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t16 features in original data used to generate 16 features in processed data.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Excluded models: ['GBM', 'RF', 'XT', 'XGB', 'CAT', 'KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting 44 L1 models ...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 596.88s of the 895.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.7911\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 590.22s of the 888.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8404\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 583.98s of the 882.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8216\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 577.68s of the 876.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8146\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 571.7s of the 870.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8286\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 564.82s of the 863.48s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8357\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 558.1s of the 856.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8122\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 552.38s of the 851.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.838\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 546.25s of the 844.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8427\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 539.59s of the 838.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8005\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 533.45s of the 832.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.7981\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 528.18s of the 826.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8169\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 523.42s of the 822.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8216\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 515.43s of the 814.1s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8192\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 507.76s of the 806.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8028\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 502.08s of the 800.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8568\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 496.39s of the 795.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.838\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 490.28s of the 788.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8263\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t6.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 481.66s of the 780.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8286\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 476.77s of the 775.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8146\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t9.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 465.27s of the 763.93s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8192\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 457.55s of the 756.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8052\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 451.04s of the 749.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8263\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 445.05s of the 743.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8052\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 437.73s of the 736.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8122\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 429.93s of the 728.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8333\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 424.6s of the 723.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 420.03s of the 718.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8568\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 413.76s of the 712.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8216\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 408.52s of the 707.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8122\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 403.23s of the 701.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8075\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 396.59s of the 695.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8099\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 389.64s of the 688.3s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 384.99s of the 683.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8404\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 377.86s of the 676.52s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8169\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 371.39s of the 670.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.7817\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 366.24s of the 664.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8263\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 359.46s of the 658.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8075\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 354.57s of the 653.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8169\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 348.86s of the 647.52s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.7934\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t8.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 338.22s of the 636.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.831\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 330.23s of the 628.89s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 325.49s of the 624.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8427\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 319.39s of the 618.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8286\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 611.4s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_r41_BAG_L1': 0.714, 'NeuralNetTorch_r86_BAG_L1': 0.143, 'NeuralNetTorch_r1_BAG_L1': 0.143}\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8615\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Excluded models: ['GBM', 'RF', 'XT', 'XGB', 'CAT', 'KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting 44 L2 models ...\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 611.32s of the 611.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8662\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 606.4s of the 606.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 600.18s of the 600.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 594.3s of the 594.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 588.3s of the 588.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 582.27s of the 582.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 575.38s of the 575.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 569.2s of the 569.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 562.22s of the 562.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 556.41s of the 556.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L2 ... Training model for up to 550.08s of the 550.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L2 ... Training model for up to 544.53s of the 544.48s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L2 ... Training model for up to 539.73s of the 539.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t6.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r156_BAG_L2 ... Training model for up to 531.36s of the 531.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r95_BAG_L2 ... Training model for up to 523.65s of the 523.6s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8662\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r41_BAG_L2 ... Training model for up to 517.74s of the 517.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r158_BAG_L2 ... Training model for up to 512.16s of the 512.11s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r37_BAG_L2 ... Training model for up to 505.93s of the 505.89s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8803\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t6.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r197_BAG_L2 ... Training model for up to 497.54s of the 497.5s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r134_BAG_L2 ... Training model for up to 492.78s of the 492.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t9.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r143_BAG_L2 ... Training model for up to 481.08s of the 481.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8709\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r111_BAG_L2 ... Training model for up to 474.31s of the 474.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r31_BAG_L2 ... Training model for up to 467.6s of the 467.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r65_BAG_L2 ... Training model for up to 462.56s of the 462.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8709\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r88_BAG_L2 ... Training model for up to 455.04s of the 454.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8803\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r87_BAG_L2 ... Training model for up to 447.03s of the 446.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8826\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r71_BAG_L2 ... Training model for up to 441.64s of the 441.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.27s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r185_BAG_L2 ... Training model for up to 436.78s of the 436.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8826\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r160_BAG_L2 ... Training model for up to 430.55s of the 430.5s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8615\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r69_BAG_L2 ... Training model for up to 424.93s of the 424.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8638\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r138_BAG_L2 ... Training model for up to 419.2s of the 419.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8803\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r172_BAG_L2 ... Training model for up to 412.09s of the 412.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r76_BAG_L2 ... Training model for up to 404.54s of the 404.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8615\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.28s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r121_BAG_L2 ... Training model for up to 399.84s of the 399.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8709\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r127_BAG_L2 ... Training model for up to 392.72s of the 392.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r194_BAG_L2 ... Training model for up to 386.13s of the 386.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8592\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r135_BAG_L2 ... Training model for up to 380.84s of the 380.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r4_BAG_L2 ... Training model for up to 374.28s of the 374.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r36_BAG_L2 ... Training model for up to 369.15s of the 369.1s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8803\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r100_BAG_L2 ... Training model for up to 363.94s of the 363.89s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t8.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetFastAI_r187_BAG_L2 ... Training model for up to 353.17s of the 353.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t5.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r19_BAG_L2 ... Training model for up to 345.29s of the 345.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8592\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t2.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r1_BAG_L2 ... Training model for up to 340.68s of the 340.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8709\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t4.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: NeuralNetTorch_r89_BAG_L2 ... Training model for up to 334.44s of the 334.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t3.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 328.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_r87_BAG_L2': 0.95, 'NeuralNetFastAI_r156_BAG_L2': 0.05}\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.885\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m AutoGluon training complete, total runtime = 567.51s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 11.1 rows/s (43 batch size)\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"GPU_1_XAPI_DL_VALIDATION_kfold\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=44444)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     NeuralNetTorch_r14_BAG_L2       0.851852   0.868545    accuracy       95.343837       3.803998  193.145435                 0.295864                0.242163           2.598941            2       True         57\n",
      "1    NeuralNetTorch_r185_BAG_L1       0.833333   0.856808    accuracy        0.517083       0.062614    4.122945                 0.517083                0.062614           4.122945            1       True         28\n",
      "2    NeuralNetFastAI_r88_BAG_L2       0.833333   0.880282    accuracy       95.301290       3.662914  196.406228                 0.253317                0.101079           5.859735            2       True         70\n",
      "3         NeuralNetTorch_BAG_L2       0.833333   0.868545    accuracy       95.338545       3.793636  194.475542                 0.290572                0.231801           3.929048            2       True         47\n",
      "4     NeuralNetTorch_r41_BAG_L2       0.833333   0.877934    accuracy       95.340918       3.804378  193.960694                 0.292945                0.242543           3.414200            2       True         61\n",
      "5     NeuralNetTorch_r31_BAG_L2       0.833333   0.868545    accuracy       95.342685       3.824440  193.338723                 0.294712                0.262605           2.792229            2       True         68\n",
      "6     NeuralNetTorch_r89_BAG_L2       0.833333   0.873239    accuracy       95.348710       3.807909  194.442622                 0.300737                0.246074           3.896128            2       True         89\n",
      "7     NeuralNetTorch_r87_BAG_L2       0.833333   0.882629    accuracy       95.371046       3.792982  193.900268                 0.323073                0.231147           3.353774            2       True         71\n",
      "8           WeightedEnsemble_L3       0.833333   0.884977    accuracy       95.650232       3.891002  199.570769                 0.006167                0.000000           0.062240            3       True         90\n",
      "9     NeuralNetTorch_r71_BAG_L1       0.814815   0.823944    accuracy        0.394249       0.066422    2.477509                 0.394249                0.066422           2.477509            1       True         27\n",
      "10    NeuralNetTorch_r86_BAG_L1       0.814815   0.842723    accuracy        0.419491       0.067979    4.566203                 0.419491                0.067979           4.566203            1       True          9\n",
      "11   NeuralNetTorch_r121_BAG_L1       0.814815   0.840376    accuracy        0.479222       0.070886    5.032215                 0.479222                0.070886           5.032215            1       True         34\n",
      "12     NeuralNetTorch_r1_BAG_L1       0.814815   0.842723    accuracy        0.491427       0.073044    3.960161                 0.491427                0.073044           3.960161            1       True         43\n",
      "13          WeightedEnsemble_L2       0.814815   0.861502    accuracy        1.331813       0.209416   12.180102                 0.006019                0.001000           0.063617            2       True         45\n",
      "14    NeuralNetFastAI_r4_BAG_L2       0.814815   0.873239    accuracy       95.279616       3.639717  193.581271                 0.231643                0.077882           3.034777            2       True         83\n",
      "15  NeuralNetFastAI_r172_BAG_L2       0.814815   0.868545    accuracy       95.312842       3.662895  195.423645                 0.264869                0.101060           4.877151            2       True         77\n",
      "16    NeuralNetTorch_r19_BAG_L2       0.814815   0.859155    accuracy       95.317565       3.803774  193.136064                 0.269593                0.241939           2.589570            2       True         87\n",
      "17   NeuralNetFastAI_r37_BAG_L2       0.814815   0.880282    accuracy       95.323842       3.668587  196.897087                 0.275869                0.106752           6.350593            2       True         63\n",
      "18   NeuralNetTorch_r197_BAG_L2       0.814815   0.868545    accuracy       95.327247       3.797939  193.276334                 0.279274                0.236104           2.729840            2       True         64\n",
      "19    NeuralNetTorch_r76_BAG_L2       0.814815   0.861502    accuracy       95.340015       3.837196  193.096941                 0.292042                0.275361           2.550447            2       True         78\n",
      "20   NeuralNetTorch_r135_BAG_L2       0.814815   0.877934    accuracy       95.342299       3.812138  194.839596                 0.294326                0.250303           4.293102            2       True         82\n",
      "21    NeuralNetTorch_r71_BAG_L2       0.814815   0.873239    accuracy       95.352435       3.827337  193.277777                 0.304462                0.265502           2.731283            2       True         72\n",
      "22    NeuralNetTorch_r22_BAG_L2       0.814815   0.868545    accuracy       95.369204       3.802587  194.460469                 0.321231                0.240752           3.913975            2       True         50\n",
      "23   NeuralNetTorch_r158_BAG_L2       0.814815   0.873239    accuracy       95.384615       3.808451  194.709966                 0.336642                0.246616           4.163472            2       True         62\n",
      "24   NeuralNetTorch_r143_BAG_L2       0.814815   0.870892    accuracy       95.393245       3.813010  195.296335                 0.345272                0.251175           4.749841            2       True         66\n",
      "25   NeuralNetTorch_r121_BAG_L2       0.814815   0.870892    accuracy       95.399359       3.802276  195.445207                 0.351386                0.240441           4.898713            2       True         79\n",
      "26    NeuralNetTorch_r86_BAG_L2       0.814815   0.873239    accuracy       95.438416       3.792023  194.357592                 0.390443                0.230188           3.811098            2       True         54\n",
      "27   NeuralNetTorch_r197_BAG_L1       0.796296   0.828638    accuracy        0.403063       0.065995    2.874298                 0.403063                0.065995           2.874298            1       True         19\n",
      "28    NeuralNetTorch_r14_BAG_L1       0.796296   0.816901    accuracy        0.404195       0.063917    2.615900                 0.404195                0.063917           2.615900            1       True         12\n",
      "29    NeuralNetTorch_r41_BAG_L1       0.796296   0.856808    accuracy        0.414876       0.067393    3.590121                 0.414876                0.067393           3.590121            1       True         16\n",
      "30   NeuralNetTorch_r158_BAG_L1       0.796296   0.838028    accuracy        0.417476       0.070790    4.056512                 0.417476                0.070790           4.056512            1       True         17\n",
      "31    NeuralNetTorch_r36_BAG_L1       0.796296   0.816901    accuracy        0.463997       0.059633    3.448687                 0.463997                0.059633           3.448687            1       True         39\n",
      "32    NeuralNetTorch_r30_BAG_L1       0.796296   0.838028    accuracy        0.469777       0.072618    3.937114                 0.469777                0.072618           3.937114            1       True          8\n",
      "33   NeuralNetFastAI_r69_BAG_L2       0.796296   0.863850    accuracy       95.274455       3.646654  193.899247                 0.226482                0.084819           3.352753            2       True         75\n",
      "34  NeuralNetFastAI_r145_BAG_L2       0.796296   0.873239    accuracy       95.292984       3.668832  194.416204                 0.245011                0.106997           3.869711            2       True         52\n",
      "35  NeuralNetFastAI_r160_BAG_L2       0.796296   0.861502    accuracy       95.295097       3.654388  194.106261                 0.247124                0.092553           3.559767            2       True         74\n",
      "36   NeuralNetFastAI_r65_BAG_L2       0.796296   0.870892    accuracy       95.301431       3.656796  195.899565                 0.253458                0.094962           5.353071            2       True         69\n",
      "37  NeuralNetFastAI_r102_BAG_L2       0.796296   0.875587    accuracy       95.303524       3.665275  195.415917                 0.255551                0.103440           4.869423            2       True         51\n",
      "38  NeuralNetFastAI_r100_BAG_L2       0.796296   0.877934    accuracy       95.306885       3.702191  199.201880                 0.258912                0.140357           8.655386            2       True         85\n",
      "39  NeuralNetFastAI_r194_BAG_L2       0.796296   0.859155    accuracy       95.311059       3.658205  193.599520                 0.263086                0.096370           3.053026            2       True         81\n",
      "40  NeuralNetFastAI_r134_BAG_L2       0.796296   0.868545    accuracy       95.312972       3.706063  200.131312                 0.264999                0.144228           9.584819            2       True         65\n",
      "41  NeuralNetFastAI_r127_BAG_L2       0.796296   0.873239    accuracy       95.320963       3.668958  195.138929                 0.272990                0.107123           4.592435            2       True         80\n",
      "42    NeuralNetTorch_r36_BAG_L2       0.796296   0.880282    accuracy       95.336270       3.804309  193.479025                 0.288297                0.242474           2.932531            2       True         84\n",
      "43  NeuralNetFastAI_r143_BAG_L2       0.796296   0.877934    accuracy       95.344084       3.659738  196.641871                 0.296111                0.097903           6.095377            2       True         58\n",
      "44   NeuralNetTorch_r185_BAG_L2       0.796296   0.882629    accuracy       95.347090       3.795406  194.687263                 0.299118                0.233572           4.140770            2       True         73\n",
      "45    NeuralNetTorch_r30_BAG_L2       0.796296   0.875587    accuracy       95.348543       3.807892  195.205954                 0.300570                0.246057           4.659460            2       True         53\n",
      "46     NeuralNetTorch_r1_BAG_L2       0.796296   0.870892    accuracy       95.356680       3.823411  194.649428                 0.308707                0.261576           4.102935            2       True         88\n",
      "47    NeuralNetTorch_r76_BAG_L1       0.777778   0.823944    accuracy        0.390149       0.064992    2.568048                 0.390149                0.064992           2.568048            1       True         33\n",
      "48    NeuralNetTorch_r19_BAG_L1       0.777778   0.823944    accuracy        0.419041       0.065164    2.680011                 0.419041                0.065164           2.680011            1       True         42\n",
      "49    NeuralNetTorch_r89_BAG_L1       0.777778   0.828638    accuracy        0.421158       0.067506    4.353945                 0.421158                0.067506           4.353945            1       True         44\n",
      "50        NeuralNetTorch_BAG_L1       0.777778   0.840376    accuracy        0.422914       0.069818    4.039881                 0.422914                0.069818           4.039881            1       True          2\n",
      "51    NeuralNetTorch_r87_BAG_L1       0.777778   0.833333    accuracy        0.427824       0.066293    3.363109                 0.427824                0.066293           3.363109            1       True         26\n",
      "52    NeuralNetTorch_r22_BAG_L1       0.777778   0.828638    accuracy        0.442045       0.075503    4.662112                 0.442045                0.075503           4.662112            1       True          5\n",
      "53    NeuralNetTorch_r79_BAG_L1       0.777778   0.821596    accuracy        0.454478       0.068762    4.004767                 0.454478                0.068762           4.004767            1       True          3\n",
      "54   NeuralNetTorch_r135_BAG_L1       0.777778   0.826291    accuracy        0.521866       0.070987    4.992745                 0.521866                0.070987           4.992745            1       True         37\n",
      "55    NeuralNetFastAI_r4_BAG_L1       0.777778   0.807512    accuracy        3.817366       0.074505    2.914057                 3.817366                0.074505           2.914057            1       True         38\n",
      "56  NeuralNetFastAI_r187_BAG_L2       0.777778   0.873239    accuracy       95.307610       3.669699  196.285330                 0.259637                0.107864           5.738836            2       True         86\n",
      "57    NeuralNetTorch_r79_BAG_L2       0.777778   0.873239    accuracy       95.331772       3.787103  194.425744                 0.283799                0.225269           3.879250            2       True         48\n",
      "58    NeuralNetTorch_r31_BAG_L1       0.759259   0.826291    accuracy        0.387615       0.069068    3.764124                 0.387615                0.069068           3.764124            1       True         23\n",
      "59  NeuralNetFastAI_r102_BAG_L1       0.759259   0.835681    accuracy        3.579346       0.098702    4.763226                 3.579346                0.098702           4.763226            1       True          6\n",
      "60   NeuralNetFastAI_r11_BAG_L1       0.759259   0.800469    accuracy        3.785304       0.100714    4.157956                 3.785304                0.100714           4.157956            1       True         10\n",
      "61       NeuralNetFastAI_BAG_L2       0.759259   0.866197    accuracy       95.271940       3.647824  193.478195                 0.223968                0.085989           2.931701            2       True         46\n",
      "62   NeuralNetFastAI_r11_BAG_L2       0.759259   0.873239    accuracy       95.279324       3.670798  194.848816                 0.231351                0.108963           4.302322            2       True         55\n",
      "63  NeuralNetFastAI_r138_BAG_L2       0.759259   0.880282    accuracy       95.284616       3.681420  195.364756                 0.236644                0.119585           4.818262            2       True         76\n",
      "64  NeuralNetFastAI_r191_BAG_L2       0.759259   0.875587    accuracy       95.291512       3.667158  194.505357                 0.243539                0.105323           3.958863            2       True         49\n",
      "65  NeuralNetFastAI_r103_BAG_L2       0.759259   0.875587    accuracy       95.307644       3.657997  193.924927                 0.259671                0.096162           3.378433            2       True         56\n",
      "66  NeuralNetFastAI_r156_BAG_L2       0.759259   0.877934    accuracy       95.320992       3.659854  196.154755                 0.273019                0.098020           5.608261            2       True         59\n",
      "67  NeuralNetFastAI_r111_BAG_L2       0.759259   0.873239    accuracy       95.321710       3.675609  195.238064                 0.273737                0.113774           4.691571            2       True         67\n",
      "68   NeuralNetTorch_r143_BAG_L1       0.740741   0.819249    accuracy        0.449990       0.071165    5.696605                 0.449990                0.071165           5.696605            1       True         21\n",
      "69   NeuralNetFastAI_r95_BAG_L2       0.740741   0.866197    accuracy       95.276706       3.652357  194.381795                 0.228733                0.090522           3.835301            2       True         60\n",
      "70   NeuralNetFastAI_r37_BAG_L1       0.722222   0.826291    accuracy        3.849907       0.095984    6.561243                 3.849907                0.095984           6.561243            1       True         18\n",
      "71  NeuralNetFastAI_r134_BAG_L1       0.703704   0.814554    accuracy        3.103105       0.130916    9.471574                 3.103105                0.130916           9.471574            1       True         20\n",
      "72  NeuralNetFastAI_r160_BAG_L1       0.703704   0.821596    accuracy        3.434996       0.077245    3.217346                 3.434996                0.077245           3.217346            1       True         29\n",
      "73  NeuralNetFastAI_r111_BAG_L1       0.703704   0.805164    accuracy        3.492844       0.103137    4.512236                 3.492844                0.103137           4.512236            1       True         22\n",
      "74  NeuralNetFastAI_r143_BAG_L1       0.703704   0.821596    accuracy        3.779235       0.090781    5.848135                 3.779235                0.090781           5.848135            1       True         13\n",
      "75  NeuralNetFastAI_r187_BAG_L1       0.703704   0.830986    accuracy        3.820929       0.088816    5.936701                 3.820929                0.088816           5.936701            1       True         41\n",
      "76   NeuralNetFastAI_r88_BAG_L1       0.703704   0.812207    accuracy        3.989442       0.089305    5.584162                 3.989442                0.089305           5.584162            1       True         25\n",
      "77  NeuralNetFastAI_r172_BAG_L1       0.703704   0.809859    accuracy        3.997420       0.089647    4.805177                 3.997420                0.089647           4.805177            1       True         32\n",
      "78   NeuralNetFastAI_r69_BAG_L1       0.703704   0.812207    accuracy        4.094962       0.075310    3.086169                 4.094962                0.075310           3.086169            1       True         30\n",
      "79  NeuralNetFastAI_r156_BAG_L1       0.685185   0.819249    accuracy        3.348256       0.089857    5.391994                 3.348256                0.089857           5.391994            1       True         14\n",
      "80  NeuralNetFastAI_r191_BAG_L1       0.685185   0.814554    accuracy        3.397342       0.097368    3.871168                 3.397342                0.097368           3.871168            1       True          4\n",
      "81  NeuralNetFastAI_r138_BAG_L1       0.685185   0.807512    accuracy        3.617525       0.090353    4.436249                 3.617525                0.090353           4.436249            1       True         31\n",
      "82  NeuralNetFastAI_r127_BAG_L1       0.685185   0.816901    accuracy        3.871330       0.098510    4.472956                 3.871330                0.098510           4.472956            1       True         35\n",
      "83  NeuralNetFastAI_r145_BAG_L1       0.685185   0.812207    accuracy        4.136640       0.075067    3.570356                 4.136640                0.075067           3.570356            1       True          7\n",
      "84  NeuralNetFastAI_r194_BAG_L1       0.666667   0.781690    accuracy        3.609929       0.085573    2.916263                 3.609929                0.085573           2.916263            1       True         36\n",
      "85       NeuralNetFastAI_BAG_L1       0.666667   0.791080    accuracy        3.966329       0.087145    3.478902                 3.966329                0.087145           3.478902            1       True          1\n",
      "86  NeuralNetFastAI_r103_BAG_L1       0.666667   0.798122    accuracy        4.199306       0.081448    3.170543                 4.199306                0.081448           3.170543            1       True         11\n",
      "87   NeuralNetFastAI_r95_BAG_L1       0.648148   0.802817    accuracy        3.519499       0.078290    3.650244                 3.519499                0.078290           3.650244            1       True         15\n",
      "88   NeuralNetFastAI_r65_BAG_L1       0.648148   0.805164    accuracy        3.947651       0.091523    5.308207                 3.947651                0.091523           5.308207            1       True         24\n",
      "89  NeuralNetFastAI_r100_BAG_L1       0.629630   0.793427    accuracy        3.477373       0.141089    8.614620                 3.477373                0.141089           8.614620            1       True         40\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t682s\t = DyStack   runtime |\t2918s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2918s\n",
      "AutoGluon will save models to \"GPU_1_XAPI_DL_VALIDATION_kfold\"\n",
      "Train Data Rows:    480\n",
      "Train Data Columns: 16\n",
      "Label Column:       Class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    48580.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    :  4 | ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']\n",
      "\t\t('object', []) : 12 | ['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', 'SectionID', ...]\n",
      "\t\t('int', [])       : 4 | ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']\n",
      "\t\t('int', ['bool']) : 6 | ['gender', 'Semester', 'Relation', 'ParentAnsweringSurvey', 'ParentschoolSatisfaction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['GBM', 'KNN', 'RF', 'CAT', 'XGB', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 44 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1944.89s of the 2918.06s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7979\t = Validation score   (accuracy)\n",
      "\t18.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1924.66s of the 2897.83s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8208\t = Validation score   (accuracy)\n",
      "\t39.32s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1883.65s of the 2856.82s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8229\t = Validation score   (accuracy)\n",
      "\t39.84s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1842.16s of the 2815.33s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7896\t = Validation score   (accuracy)\n",
      "\t19.22s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1821.25s of the 2794.42s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8\t = Validation score   (accuracy)\n",
      "\t41.91s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1777.73s of the 2750.91s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t27.67s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1748.45s of the 2721.62s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8042\t = Validation score   (accuracy)\n",
      "\t20.83s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1725.95s of the 2699.12s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8167\t = Validation score   (accuracy)\n",
      "\t47.95s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1676.27s of the 2649.44s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8417\t = Validation score   (accuracy)\n",
      "\t39.79s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 1634.85s of the 2608.02s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8062\t = Validation score   (accuracy)\n",
      "\t22.24s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 1610.91s of the 2584.08s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7896\t = Validation score   (accuracy)\n",
      "\t18.88s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 1590.33s of the 2563.5s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8354\t = Validation score   (accuracy)\n",
      "\t34.72s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 1553.88s of the 2527.05s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7958\t = Validation score   (accuracy)\n",
      "\t31.12s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 1521.08s of the 2494.25s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t29.83s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 1489.55s of the 2462.72s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8042\t = Validation score   (accuracy)\n",
      "\t20.95s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 1466.93s of the 2440.1s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8292\t = Validation score   (accuracy)\n",
      "\t38.18s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 1427.11s of the 2400.28s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8208\t = Validation score   (accuracy)\n",
      "\t44.41s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 1381.11s of the 2354.28s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t34.17s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 1345.26s of the 2318.43s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.825\t = Validation score   (accuracy)\n",
      "\t33.56s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 1310.05s of the 2283.22s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8208\t = Validation score   (accuracy)\n",
      "\t40.71s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 1267.65s of the 2240.82s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8271\t = Validation score   (accuracy)\n",
      "\t58.32s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 1207.72s of the 2180.9s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7854\t = Validation score   (accuracy)\n",
      "\t26.33s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 1179.75s of the 2152.92s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t36.83s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 1141.19s of the 2114.36s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8021\t = Validation score   (accuracy)\n",
      "\t30.31s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 1109.25s of the 2082.42s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8042\t = Validation score   (accuracy)\n",
      "\t28.32s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 1079.24s of the 2052.41s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8292\t = Validation score   (accuracy)\n",
      "\t38.73s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 1038.88s of the 2012.05s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8396\t = Validation score   (accuracy)\n",
      "\t31.75s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 1005.57s of the 1978.74s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t42.39s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 961.51s of the 1934.68s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7833\t = Validation score   (accuracy)\n",
      "\t19.77s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 940.07s of the 1913.24s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t19.34s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 919.05s of the 1892.22s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8021\t = Validation score   (accuracy)\n",
      "\t23.31s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 894.03s of the 1867.2s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t29.0s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 863.29s of the 1836.46s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8562\t = Validation score   (accuracy)\n",
      "\t34.84s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 826.77s of the 1799.94s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8396\t = Validation score   (accuracy)\n",
      "\t44.36s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 780.75s of the 1753.92s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8146\t = Validation score   (accuracy)\n",
      "\t27.44s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 751.58s of the 1724.76s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.775\t = Validation score   (accuracy)\n",
      "\t18.16s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 731.67s of the 1704.84s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8354\t = Validation score   (accuracy)\n",
      "\t47.33s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 682.69s of the 1655.86s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8062\t = Validation score   (accuracy)\n",
      "\t18.3s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 662.74s of the 1635.91s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8083\t = Validation score   (accuracy)\n",
      "\t36.86s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 624.19s of the 1597.36s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7792\t = Validation score   (accuracy)\n",
      "\t37.02s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 585.52s of the 1558.69s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8062\t = Validation score   (accuracy)\n",
      "\t30.07s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 553.71s of the 1526.88s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8375\t = Validation score   (accuracy)\n",
      "\t33.69s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 518.38s of the 1491.56s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8333\t = Validation score   (accuracy)\n",
      "\t42.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 473.94s of the 1447.11s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8375\t = Validation score   (accuracy)\n",
      "\t43.21s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1402.04s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r76_BAG_L1': 0.5, 'NeuralNetTorch_r86_BAG_L1': 0.167, 'NeuralNetFastAI_r156_BAG_L1': 0.167, 'NeuralNetTorch_r185_BAG_L1': 0.083, 'NeuralNetTorch_r121_BAG_L1': 0.083}\n",
      "\t0.8646\t = Validation score   (accuracy)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['GBM', 'KNN', 'RF', 'CAT', 'XGB', 'XT'] (Specified by `excluded_model_types`)\n",
      "Fitting 44 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1401.92s of the 1401.86s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8646\t = Validation score   (accuracy)\n",
      "\t18.38s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1381.86s of the 1381.8s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t35.82s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 1344.32s of the 1344.25s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t41.6s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 1301.02s of the 1300.96s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t19.82s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 1279.42s of the 1279.36s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8667\t = Validation score   (accuracy)\n",
      "\t38.58s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 1239.21s of the 1239.15s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8625\t = Validation score   (accuracy)\n",
      "\t27.69s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 1209.83s of the 1209.77s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t20.55s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 1187.52s of the 1187.46s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8771\t = Validation score   (accuracy)\n",
      "\t40.9s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 1144.94s of the 1144.88s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t36.38s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 1106.91s of the 1106.84s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t21.84s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L2 ... Training model for up to 1083.39s of the 1083.33s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8562\t = Validation score   (accuracy)\n",
      "\t18.18s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L2 ... Training model for up to 1063.51s of the 1063.44s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t30.84s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L2 ... Training model for up to 1030.97s of the 1030.9s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t29.37s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L2 ... Training model for up to 999.84s of the 999.77s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t27.26s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L2 ... Training model for up to 970.84s of the 970.77s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t20.39s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L2 ... Training model for up to 948.77s of the 948.71s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8625\t = Validation score   (accuracy)\n",
      "\t34.76s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L2 ... Training model for up to 912.35s of the 912.29s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t40.55s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L2 ... Training model for up to 870.21s of the 870.15s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t29.2s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L2 ... Training model for up to 839.34s of the 839.28s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8583\t = Validation score   (accuracy)\n",
      "\t32.27s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L2 ... Training model for up to 805.28s of the 805.22s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8812\t = Validation score   (accuracy)\n",
      "\t34.05s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L2 ... Training model for up to 769.6s of the 769.54s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t43.45s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L2 ... Training model for up to 724.46s of the 724.39s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t26.29s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L2 ... Training model for up to 696.5s of the 696.44s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8646\t = Validation score   (accuracy)\n",
      "\t33.61s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L2 ... Training model for up to 661.21s of the 661.14s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8771\t = Validation score   (accuracy)\n",
      "\t28.86s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L2 ... Training model for up to 630.6s of the 630.54s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t28.63s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L2 ... Training model for up to 600.28s of the 600.22s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t35.78s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L2 ... Training model for up to 562.81s of the 562.74s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8562\t = Validation score   (accuracy)\n",
      "\t31.75s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L2 ... Training model for up to 529.36s of the 529.3s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8667\t = Validation score   (accuracy)\n",
      "\t37.29s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L2 ... Training model for up to 490.39s of the 490.32s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t20.0s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L2 ... Training model for up to 468.69s of the 468.63s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t19.66s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L2 ... Training model for up to 447.31s of the 447.24s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t22.73s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L2 ... Training model for up to 422.86s of the 422.79s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8667\t = Validation score   (accuracy)\n",
      "\t26.79s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L2 ... Training model for up to 394.36s of the 394.3s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t32.15s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L2 ... Training model for up to 360.57s of the 360.51s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t40.15s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L2 ... Training model for up to 318.74s of the 318.67s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t27.06s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L2 ... Training model for up to 290.02s of the 289.96s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8625\t = Validation score   (accuracy)\n",
      "\t18.16s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L2 ... Training model for up to 270.12s of the 270.05s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t42.69s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L2 ... Training model for up to 225.79s of the 225.73s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t18.02s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L2 ... Training model for up to 206.09s of the 206.03s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t35.66s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L2 ... Training model for up to 168.77s of the 168.71s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8771\t = Validation score   (accuracy)\n",
      "\t35.81s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L2 ... Training model for up to 131.22s of the 131.15s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8792\t = Validation score   (accuracy)\n",
      "\t29.32s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L2 ... Training model for up to 100.09s of the 100.02s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t32.74s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L2 ... Training model for up to 65.69s of the 65.62s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t39.13s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L2 ... Training model for up to 24.91s of the 24.84s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8583\t = Validation score   (accuracy)\n",
      "\t38.09s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -15.12s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_r134_BAG_L2': 0.75, 'NeuralNetTorch_r30_BAG_L2': 0.25}\n",
      "\t0.8854\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2933.38s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 14.1 rows/s (48 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"GPU_1_XAPI_DL_VALIDATION_kfold\")\n",
      "C:\\Users\\JAL\\AppData\\Local\\Temp\\ipykernel_34308\\1798998893.py:63: DeprecationWarning: `get_oof_pred` has been deprecated and will be removed in version 1.2. Please use `predict_oof` instead. This will raise an error in the future!\n",
      "  oof_pred = predictor.get_oof_pred()\n",
      "C:\\Users\\JAL\\AppData\\Local\\Temp\\ipykernel_34308\\1798998893.py:76: DeprecationWarning: `get_oof_pred_proba` has been deprecated and will be removed in version 1.2. Please use `predict_proba_oof` instead. This will raise an error in the future!\n",
      "  proba_oof = predictor.get_oof_pred_proba()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TabularPredictor' object has no attribute 'get_cross_validation_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m roc_auc_oof \u001b[38;5;241m=\u001b[39m roc_auc_score(one_hot_true, proba_oof, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# (B) Summary of cross-validation metrics\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cross_validation_scores\u001b[49m(probabilities\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Store OOF metrics in a DataFrame\u001b[39;00m\n\u001b[0;32m     84\u001b[0m df_oof_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy (OOF)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision (OOF)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall (OOF)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 Score (OOF)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROC AUC (OOF)\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m'\u001b[39m: [accuracy_oof, precision_oof, recall_oof, f1_oof, roc_auc_oof]\n\u001b[0;32m     87\u001b[0m })\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TabularPredictor' object has no attribute 'get_cross_validation_scores'"
     ]
    }
   ],
   "source": [
    "FILENAME = \"XAPI\"\n",
    "DATA_PATH = \"xapi.csv\"\n",
    "TARGET = \"Class\"\n",
    "KFOLD = 10  # Number of folds for cross-validation\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# Remove spaces in column names (if any)\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "# Create a DataFrame including features and target\n",
    "df_selected = X.copy()\n",
    "df_selected[TARGET] = y\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "gpu_available = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "validation_type = 'kfold'\n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "# Define output directory\n",
    "path = f\"GPU_{gpu_available}_{FILENAME}_DL_VALIDATION_{validation_type}\"\n",
    "# If the directory already exists, delete it before creating a new one\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)  # Remove previous results\n",
    "#os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Create AutoGluon predictor\n",
    "predictor = TabularPredictor(\n",
    "    label=TARGET, \n",
    "    path=path, \n",
    "    problem_type=\"multiclass\",\n",
    ")\n",
    "\n",
    "# Fit models using AutoGluon with 10-fold bagging\n",
    "if gpu_available:\n",
    "    predictor.fit(\n",
    "        df_selected,\n",
    "        num_bag_folds=KFOLD,\n",
    "        verbosity=2,\n",
    "        num_gpus=1,\n",
    "        excluded_model_types=['RF', 'KNN', 'GBM', 'XGB', 'CAT', 'XT', 'LR'],\n",
    "        presets=\"best_quality\"\n",
    "    )\n",
    "else:\n",
    "    predictor.fit(\n",
    "        df_selected,\n",
    "        num_bag_folds=KFOLD,\n",
    "        verbosity=2,\n",
    "        excluded_model_types=['RF', 'KNN', 'GBM', 'XGB', 'CAT', 'XT', 'LR'],\n",
    "        presets=\"best_quality\"\n",
    "    )\n",
    "\n",
    "####\n",
    "# (A) Retrieve Out-Of-Fold (OOF) predictions\n",
    "####\n",
    "# This DataFrame contains predictions made for each instance when it was in the validation set of a given fold\n",
    "oof_pred = predictor.get_oof_pred()\n",
    "\n",
    "# Retrieve true labels corresponding to OOF predictions\n",
    "y_true_oof = df_selected.loc[oof_pred.index, TARGET]\n",
    "\n",
    "# Compute OOF metrics\n",
    "accuracy_oof = accuracy_score(y_true_oof, oof_pred)\n",
    "precision_oof = precision_score(y_true_oof, oof_pred, average='weighted')\n",
    "recall_oof = recall_score(y_true_oof, oof_pred, average='weighted')\n",
    "f1_oof = f1_score(y_true_oof, oof_pred, average='weighted')\n",
    "\n",
    "# For multi-class ROC-AUC:\n",
    "# predictor.get_oof_pred_proba() -> Then compute roc_auc_score\n",
    "proba_oof = predictor.get_oof_pred_proba()\n",
    "one_hot_true = pd.get_dummies(y_true_oof, drop_first=False)\n",
    "roc_auc_oof = roc_auc_score(one_hot_true, proba_oof, average='weighted', multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Metrics saved to: GPU_1_XAPI_OOF_RESULTS_kfold_66.98.csv\n",
      "Final Metrics saved to: GPU_1_XAPI_FINAL_RESULTS_kfold_66.98.csv\n",
      "CV Scores summary:                           model  score_val eval_metric  pred_time_val  \\\n",
      "0           WeightedEnsemble_L3   0.885417    accuracy       3.396184   \n",
      "1   NeuralNetFastAI_r134_BAG_L2   0.881250    accuracy       3.219157   \n",
      "2   NeuralNetFastAI_r187_BAG_L2   0.879167    accuracy       3.219671   \n",
      "3    NeuralNetFastAI_r65_BAG_L2   0.877083    accuracy       3.217616   \n",
      "4   NeuralNetFastAI_r100_BAG_L2   0.877083    accuracy       3.234588   \n",
      "..                          ...        ...         ...            ...   \n",
      "85  NeuralNetFastAI_r191_BAG_L1   0.789583    accuracy       0.085309   \n",
      "86  NeuralNetFastAI_r111_BAG_L1   0.785417    accuracy       0.094197   \n",
      "87  NeuralNetFastAI_r160_BAG_L1   0.783333    accuracy       0.085326   \n",
      "88  NeuralNetFastAI_r100_BAG_L1   0.779167    accuracy       0.091905   \n",
      "89  NeuralNetFastAI_r194_BAG_L1   0.775000    accuracy       0.078973   \n",
      "\n",
      "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   1517.443671                0.001003           0.076638            3   \n",
      "1   1476.470710                0.093975          34.050183            2   \n",
      "2   1471.740649                0.094489          29.320122            2   \n",
      "3   1471.283671                0.092434          28.863143            2   \n",
      "4   1478.234061                0.109406          35.813534            2   \n",
      "..          ...                     ...                ...          ...   \n",
      "85    19.224029                0.085309          19.224029            1   \n",
      "86    26.329521                0.094197          26.329521            1   \n",
      "87    19.773329                0.085326          19.773329            1   \n",
      "88    37.023017                0.091905          37.023017            1   \n",
      "89    18.156120                0.078973          18.156120            1   \n",
      "\n",
      "    can_infer  fit_order  ...  \\\n",
      "0        True         90  ...   \n",
      "1        True         65  ...   \n",
      "2        True         86  ...   \n",
      "3        True         69  ...   \n",
      "4        True         85  ...   \n",
      "..        ...        ...  ...   \n",
      "85       True          4  ...   \n",
      "86       True         22  ...   \n",
      "87       True         29  ...   \n",
      "88       True         40  ...   \n",
      "89       True         36  ...   \n",
      "\n",
      "                                                                                               hyperparameters  \\\n",
      "0   {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "1    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "2    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "3    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "4    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "..                                                                                                         ...   \n",
      "85   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "86   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "87   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "88   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "89   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "\n",
      "    hyperparameters_fit  \\\n",
      "0                    {}   \n",
      "1                    {}   \n",
      "2                    {}   \n",
      "3                    {}   \n",
      "4                    {}   \n",
      "..                  ...   \n",
      "85                   {}   \n",
      "86                   {}   \n",
      "87                   {}   \n",
      "88                   {}   \n",
      "89                   {}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                            ag_args_fit  \\\n",
      "0   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
      "85  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "86  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "87  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "88  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "89  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   features  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                      [NeuralNetTorch_r30_BAG_L2_1, NeuralNetFastAI_r134_BAG_L2_2, NeuralNetTorch_r30_BAG_L2_2, NeuralNetFastAI_r134_BAG_L2_1, NeuralNetTorch_r30_BAG_L2_0, NeuralNetFastAI_r134_BAG_L2_0]   \n",
      "1   [NeuralNetTorch_r135_BAG_L1_2, NeuralNetTorch_r89_BAG_L1_0, NeuralNetTorch_r22_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_2, NeuralNetTorch_r71_BAG_L1_1, NeuralNetFastAI_r134_BAG_L1_2, gender, NeuralNetFastAI_r102_BAG_L1_0, NeuralNetTorch_r121_BAG_L1_1, NeuralNetTorch_r121_BAG_L1_0, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetFastAI_r69_BAG_L1_1, Discussion, NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r172_BAG_L1_0, NeuralNetTorch_r135_BAG_L1_1, NeuralNetTorch_r76_BAG_L1_2, NeuralNetFastAI_r172_BAG_L1_2, NeuralNetFastAI_r88_BAG_L1_0, NeuralNetFastAI_r102_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_0, Neura...   \n",
      "2   [NeuralNetTorch_r135_BAG_L1_2, NeuralNetTorch_r89_BAG_L1_0, NeuralNetTorch_r22_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_2, NeuralNetTorch_r71_BAG_L1_1, NeuralNetFastAI_r134_BAG_L1_2, gender, NeuralNetFastAI_r102_BAG_L1_0, NeuralNetTorch_r121_BAG_L1_1, NeuralNetTorch_r121_BAG_L1_0, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetFastAI_r69_BAG_L1_1, Discussion, NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r172_BAG_L1_0, NeuralNetTorch_r135_BAG_L1_1, NeuralNetTorch_r76_BAG_L1_2, NeuralNetFastAI_r172_BAG_L1_2, NeuralNetFastAI_r88_BAG_L1_0, NeuralNetFastAI_r102_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_0, Neura...   \n",
      "3   [NeuralNetTorch_r135_BAG_L1_2, NeuralNetTorch_r89_BAG_L1_0, NeuralNetTorch_r22_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_2, NeuralNetTorch_r71_BAG_L1_1, NeuralNetFastAI_r134_BAG_L1_2, gender, NeuralNetFastAI_r102_BAG_L1_0, NeuralNetTorch_r121_BAG_L1_1, NeuralNetTorch_r121_BAG_L1_0, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetFastAI_r69_BAG_L1_1, Discussion, NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r172_BAG_L1_0, NeuralNetTorch_r135_BAG_L1_1, NeuralNetTorch_r76_BAG_L1_2, NeuralNetFastAI_r172_BAG_L1_2, NeuralNetFastAI_r88_BAG_L1_0, NeuralNetFastAI_r102_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_0, Neura...   \n",
      "4   [NeuralNetTorch_r135_BAG_L1_2, NeuralNetTorch_r89_BAG_L1_0, NeuralNetTorch_r22_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_2, NeuralNetTorch_r71_BAG_L1_1, NeuralNetFastAI_r134_BAG_L1_2, gender, NeuralNetFastAI_r102_BAG_L1_0, NeuralNetTorch_r121_BAG_L1_1, NeuralNetTorch_r121_BAG_L1_0, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetFastAI_r69_BAG_L1_1, Discussion, NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r172_BAG_L1_0, NeuralNetTorch_r135_BAG_L1_1, NeuralNetTorch_r76_BAG_L1_2, NeuralNetFastAI_r172_BAG_L1_2, NeuralNetFastAI_r88_BAG_L1_0, NeuralNetFastAI_r102_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_0, Neura...   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
      "85                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "86                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "87                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "88                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "89                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "\n",
      "    compile_time  \\\n",
      "0           None   \n",
      "1           None   \n",
      "2           None   \n",
      "3           None   \n",
      "4           None   \n",
      "..           ...   \n",
      "85          None   \n",
      "86          None   \n",
      "87          None   \n",
      "88          None   \n",
      "89          None   \n",
      "\n",
      "                                                                                                                                                                                                               child_hyperparameters  \\\n",
      "0                                                                                                                                                                                   {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
      "1       {'layers': [800, 400], 'emb_drop': 0.006251885504130949, 'ps': 0.2677080696008348, 'bs': 2048, 'lr': 0.01329622020483052, 'epochs': 47, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "2   {'layers': [200, 100, 50], 'emb_drop': 0.5074958658302495, 'ps': 0.34814978753283593, 'bs': 1024, 'lr': 0.026342427824862867, 'epochs': 42, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "3           {'layers': [400], 'emb_drop': 0.22771721361129746, 'ps': 0.3734259772256502, 'bs': 1024, 'lr': 0.0005383511954451698, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "4      {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "..                                                                                                                                                                                                                               ...   \n",
      "85        {'layers': [800, 400], 'emb_drop': 0.5411770367537934, 'ps': 0.23782946566604385, 'bs': 256, 'lr': 0.01519848858318159, 'epochs': 43, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "86       {'layers': [400, 200], 'emb_drop': 0.6343202884164582, 'ps': 0.48362560779595565, 'bs': 2048, 'lr': 0.08479209380262258, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "87    {'layers': [400, 200, 100], 'emb_drop': 0.3171659718142149, 'ps': 0.5909644730871169, 'bs': 128, 'lr': 0.03087210106068273, 'epochs': 20, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "88     {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "89   {'layers': [400, 200, 100], 'emb_drop': 0.5117456464220826, 'ps': 0.2747013981281539, 'bs': 256, 'lr': 0.007212882302137526, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "\n",
      "           child_hyperparameters_fit  \\\n",
      "0               {'ensemble_size': 4}   \n",
      "1    {'epochs': 47, 'best_epoch': 6}   \n",
      "2    {'epochs': 42, 'best_epoch': 4}   \n",
      "3    {'epochs': 38, 'best_epoch': 8}   \n",
      "4    {'epochs': 38, 'best_epoch': 7}   \n",
      "..                               ...   \n",
      "85  {'epochs': 43, 'best_epoch': 14}   \n",
      "86   {'epochs': 21, 'best_epoch': 9}   \n",
      "87   {'epochs': 20, 'best_epoch': 7}   \n",
      "88  {'epochs': 38, 'best_epoch': 16}   \n",
      "89   {'epochs': 21, 'best_epoch': 9}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                              child_ag_args_fit  \\\n",
      "0                                           {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
      "85  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "86  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "87  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "88  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "89  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ancestors  \\\n",
      "0   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetFastAI_r134_BAG_L2, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFast...   \n",
      "1   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r194_BAG_L1, NeuralNetTo...   \n",
      "2   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r194_BAG_L1, NeuralNetTo...   \n",
      "3   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r194_BAG_L1, NeuralNetTo...   \n",
      "4   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r194_BAG_L1, NeuralNetTo...   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
      "85                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "86                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "87                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "88                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "89                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                descendants  \n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [WeightedEnsemble_L3]  \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...  \n",
      "85  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "86  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "87  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "88  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "89  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "\n",
      "[90 rows x 32 columns]\n",
      "Execution time (min): 66.97926339308421\n"
     ]
    }
   ],
   "source": [
    "# (B) Summary of cross-validation metrics\n",
    "cv_scores = predictor.leaderboard(extra_info=True)\n",
    "\n",
    "# Store OOF metrics in a DataFrame\n",
    "df_oof_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy (OOF)', 'Precision (OOF)', 'Recall (OOF)', 'F1 Score (OOF)', 'ROC AUC (OOF)'],\n",
    "    'Score': [accuracy_oof, precision_oof, recall_oof, f1_oof, roc_auc_oof]\n",
    "})\n",
    "\n",
    "####\n",
    "# (C) Evaluate model on the full training dataset (not a true test set)\n",
    "####\n",
    "y_pred_final = predictor.predict(df_selected)\n",
    "y_prob_final = predictor.predict_proba(df_selected)\n",
    "\n",
    "accuracy_final = accuracy_score(df_selected[TARGET], y_pred_final)\n",
    "precision_final = precision_score(df_selected[TARGET], y_pred_final, average='weighted')\n",
    "recall_final = recall_score(df_selected[TARGET], y_pred_final, average='weighted')\n",
    "f1_final = f1_score(df_selected[TARGET], y_pred_final, average='weighted')\n",
    "\n",
    "# For multi-class ROC-AUC:\n",
    "roc_auc_final = roc_auc_score(pd.get_dummies(df_selected[TARGET]), \n",
    "                                y_prob_final, \n",
    "                                average='weighted', \n",
    "                                multi_class='ovr')\n",
    "\n",
    "# Store final evaluation metrics in a DataFrame\n",
    "df_final_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy (Final)', 'Precision (Final)', 'Recall (Final)', 'F1 Score (Final)', 'ROC AUC (Final)'],\n",
    "    'Score': [accuracy_final, precision_final, recall_final, f1_final, roc_auc_final]\n",
    "})\n",
    "\n",
    "# Save results to CSV files\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "\n",
    "filename_oof = f\"GPU_{gpu_available}_{FILENAME}_OOF_RESULTS_{validation_type}_{execution_time_minutes:.2f}.csv\"\n",
    "filename_final = f\"GPU_{gpu_available}_{FILENAME}_FINAL_RESULTS_{validation_type}_{execution_time_minutes:.2f}.csv\"\n",
    "\n",
    "df_oof_metrics.to_csv(filename_oof, index=False)\n",
    "df_final_metrics.to_csv(filename_final, index=False)\n",
    "\n",
    "print(\"OOF Metrics saved to:\", filename_oof)\n",
    "print(\"Final Metrics saved to:\", filename_final)\n",
    "print(\"CV Scores summary:\", cv_scores)\n",
    "print(\"Execution time (min):\", execution_time_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: ['NeuralNetFastAI_BAG_L1', 'NeuralNetTorch_BAG_L1', 'NeuralNetTorch_r79_BAG_L1', 'NeuralNetFastAI_r191_BAG_L1', 'NeuralNetTorch_r22_BAG_L1', 'NeuralNetFastAI_r102_BAG_L1', 'NeuralNetFastAI_r145_BAG_L1', 'NeuralNetTorch_r30_BAG_L1', 'NeuralNetTorch_r86_BAG_L1', 'NeuralNetFastAI_r11_BAG_L1', 'NeuralNetFastAI_r103_BAG_L1', 'NeuralNetTorch_r14_BAG_L1', 'NeuralNetFastAI_r143_BAG_L1', 'NeuralNetFastAI_r156_BAG_L1', 'NeuralNetFastAI_r95_BAG_L1', 'NeuralNetTorch_r41_BAG_L1', 'NeuralNetTorch_r158_BAG_L1', 'NeuralNetFastAI_r37_BAG_L1', 'NeuralNetTorch_r197_BAG_L1', 'NeuralNetFastAI_r134_BAG_L1', 'NeuralNetTorch_r143_BAG_L1', 'NeuralNetFastAI_r111_BAG_L1', 'NeuralNetTorch_r31_BAG_L1', 'NeuralNetFastAI_r65_BAG_L1', 'NeuralNetFastAI_r88_BAG_L1', 'NeuralNetTorch_r87_BAG_L1', 'NeuralNetTorch_r71_BAG_L1', 'NeuralNetTorch_r185_BAG_L1', 'NeuralNetFastAI_r160_BAG_L1', 'NeuralNetFastAI_r69_BAG_L1', 'NeuralNetFastAI_r138_BAG_L1', 'NeuralNetFastAI_r172_BAG_L1', 'NeuralNetTorch_r76_BAG_L1', 'NeuralNetTorch_r121_BAG_L1', 'NeuralNetFastAI_r127_BAG_L1', 'NeuralNetFastAI_r194_BAG_L1', 'NeuralNetTorch_r135_BAG_L1', 'NeuralNetFastAI_r4_BAG_L1', 'NeuralNetTorch_r36_BAG_L1', 'NeuralNetFastAI_r100_BAG_L1', 'NeuralNetFastAI_r187_BAG_L1', 'NeuralNetTorch_r19_BAG_L1', 'NeuralNetTorch_r1_BAG_L1', 'NeuralNetTorch_r89_BAG_L1', 'WeightedEnsemble_L2', 'NeuralNetFastAI_BAG_L2', 'NeuralNetTorch_BAG_L2', 'NeuralNetTorch_r79_BAG_L2', 'NeuralNetFastAI_r191_BAG_L2', 'NeuralNetTorch_r22_BAG_L2', 'NeuralNetFastAI_r102_BAG_L2', 'NeuralNetFastAI_r145_BAG_L2', 'NeuralNetTorch_r30_BAG_L2', 'NeuralNetTorch_r86_BAG_L2', 'NeuralNetFastAI_r11_BAG_L2', 'NeuralNetFastAI_r103_BAG_L2', 'NeuralNetTorch_r14_BAG_L2', 'NeuralNetFastAI_r143_BAG_L2', 'NeuralNetFastAI_r156_BAG_L2', 'NeuralNetFastAI_r95_BAG_L2', 'NeuralNetTorch_r41_BAG_L2', 'NeuralNetTorch_r158_BAG_L2', 'NeuralNetFastAI_r37_BAG_L2', 'NeuralNetTorch_r197_BAG_L2', 'NeuralNetFastAI_r134_BAG_L2', 'NeuralNetTorch_r143_BAG_L2', 'NeuralNetFastAI_r111_BAG_L2', 'NeuralNetTorch_r31_BAG_L2', 'NeuralNetFastAI_r65_BAG_L2', 'NeuralNetFastAI_r88_BAG_L2', 'NeuralNetTorch_r87_BAG_L2', 'NeuralNetTorch_r71_BAG_L2', 'NeuralNetTorch_r185_BAG_L2', 'NeuralNetFastAI_r160_BAG_L2', 'NeuralNetFastAI_r69_BAG_L2', 'NeuralNetFastAI_r138_BAG_L2', 'NeuralNetFastAI_r172_BAG_L2', 'NeuralNetTorch_r76_BAG_L2', 'NeuralNetTorch_r121_BAG_L2', 'NeuralNetFastAI_r127_BAG_L2', 'NeuralNetFastAI_r194_BAG_L2', 'NeuralNetTorch_r135_BAG_L2', 'NeuralNetFastAI_r4_BAG_L2', 'NeuralNetTorch_r36_BAG_L2', 'NeuralNetFastAI_r100_BAG_L2', 'NeuralNetFastAI_r187_BAG_L2', 'NeuralNetTorch_r19_BAG_L2', 'NeuralNetTorch_r1_BAG_L2', 'NeuralNetTorch_r89_BAG_L2', 'WeightedEnsemble_L3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAL\\AppData\\Local\\Temp\\ipykernel_34308\\3445219386.py:19: DeprecationWarning: `get_model_names` has been deprecated and will be removed in version 1.2. Please use `model_names` instead. This will raise an error in the future!\n",
      "  model_names = predictor.get_model_names()\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# MODEL INSPECTION SCRIPT\n",
    "# ==========================\n",
    "\n",
    "# This script retrieves information about trained AutoGluon models, including:\n",
    "# Listing all trained models.\n",
    "# Extracting hyperparameters from a specific model.\n",
    "# Getting detailed training information.\n",
    "# Saving hyperparameters to a JSON file.\n",
    "# Displaying a full model summary.\n",
    "\n",
    "# ==========================\n",
    "# 1. List all trained models\n",
    "# ==========================\n",
    "# AutoGluon trains multiple models (e.g., stacked, bagged, ensembles).\n",
    "# This command lists all trained models in the predictor.\n",
    "model_names = predictor.get_model_names()\n",
    "print(\"Available Models:\", model_names)\n",
    "# Example output: \n",
    "# ['WeightedEnsemble_L2', \n",
    "# 'LightGBMXT_BAG_L1', \n",
    "# 'LightGBM_BAG_L1', \n",
    "# 'NeuralNetMXNet_BAG_L1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAL\\AppData\\Local\\Temp\\ipykernel_34308\\2089814955.py:4: DeprecationWarning: `get_model_best` has been deprecated and will be removed in version 1.2. Please use `model_best` instead. This will raise an error in the future!\n",
      "  best_model_name = predictor.get_model_best()  # Get the name of the best-performing model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: WeightedEnsemble_L3\n",
      "Hyperparameters of the best model: {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 2. Get hyperparameters of a specific model\n",
    "# ==========================\n",
    "best_model_name = predictor.get_model_best()  # Get the name of the best-performing model\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "# Retrieve hyperparameters of the best-performing model\n",
    "model_info = predictor.info()\n",
    "best_model_hyperparameters = model_info['model_info'][best_model_name]['hyperparameters']\n",
    "print(f\"Hyperparameters of the best model: {best_model_hyperparameters}\")\n",
    "#Example output: Hyperparameters of the best model:\n",
    "# {'use_orig_features': False, \n",
    "# 'max_base_models': 25, \n",
    "# 'max_base_models_per_type': 5, \n",
    "# 'save_bag_folds': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training details of WeightedEnsemble_L3:\n",
      "{'name': 'WeightedEnsemble_L3', 'model_type': 'WeightedEnsembleModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.07663822174072266, 'num_classes': 3, 'quantile_levels': None, 'predict_time': 0.0010030269622802734, 'val_score': 0.8854166666666666, 'hyperparameters': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'hyperparameters_fit': {}, 'hyperparameters_nondefault': ['save_bag_folds'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 6, 'features': ['NeuralNetTorch_r30_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_2', 'NeuralNetTorch_r30_BAG_L2_2', 'NeuralNetFastAI_r134_BAG_L2_1', 'NeuralNetTorch_r30_BAG_L2_0', 'NeuralNetFastAI_r134_BAG_L2_0'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x00000199481A5A10>, 'memory_size': 26017, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'bagged_info': {'child_model_type': 'GreedyWeightedEnsembleModel', 'num_child_models': 1, 'child_model_names': ['S1F1'], '_n_repeats': 1, '_k_per_n_repeat': [1], '_random_state': 3, 'low_memory': False, 'bagged_mode': False, 'max_memory_size': 26017, 'min_memory_size': 26017, 'child_hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'child_hyperparameters_fit': {'ensemble_size': 4}, 'child_ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}}, 'stacker_info': {'num_base_models': 2, 'base_model_names': ['NeuralNetTorch_r30_BAG_L2', 'NeuralNetFastAI_r134_BAG_L2']}, 'children_info': {'S1F1': {'name': 'S1F1', 'model_type': 'GreedyWeightedEnsembleModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.07663822174072266, 'num_classes': 3, 'quantile_levels': None, 'predict_time': None, 'val_score': None, 'hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'hyperparameters_fit': {'ensemble_size': 4}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 6, 'features': ['NeuralNetTorch_r30_BAG_L2_0', 'NeuralNetTorch_r30_BAG_L2_1', 'NeuralNetTorch_r30_BAG_L2_2', 'NeuralNetFastAI_r134_BAG_L2_0', 'NeuralNetFastAI_r134_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_2'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x00000199481A7690>, 'memory_size': 7343, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'model_weights': {'NeuralNetTorch_r30_BAG_L2': 0.25, 'NeuralNetFastAI_r134_BAG_L2': 0.75}}}}\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Get model-specific training details\n",
    "# ==========================\n",
    "# Retrieve additional information about the model (training time, memory usage, etc.)\n",
    "model_name = best_model_name  # or specify any other model name\n",
    "model_info = predictor.info()\n",
    "training_details = model_info['model_info'][model_name]\n",
    "print(f\"Training details of {model_name}:\")\n",
    "print(training_details)\n",
    "\n",
    "# This may include:\n",
    "# - Training time\n",
    "# - Memory usage\n",
    "# - Number of layers\n",
    "# - Loss function used\n",
    "# - Epochs trained\n",
    "# Example output:\n",
    "# {'name': 'WeightedEnsemble_L3', 'model_type': 'WeightedEnsembleModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.07663822174072266, 'num_classes': 3, 'quantile_levels': None, 'predict_time': 0.0010030269622802734, 'val_score': 0.8854166666666666, 'hyperparameters': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'hyperparameters_fit': {}, 'hyperparameters_nondefault': ['save_bag_folds'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 6, 'features': ['NeuralNetTorch_r30_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_2', 'NeuralNetTorch_r30_BAG_L2_2', 'NeuralNetFastAI_r134_BAG_L2_1', 'NeuralNetTorch_r30_BAG_L2_0', 'NeuralNetFastAI_r134_BAG_L2_0'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x00000199481A5A10>, 'memory_size': 26017, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'bagged_info': {'child_model_type': 'GreedyWeightedEnsembleModel', 'num_child_models': 1, 'child_model_names': ['S1F1'], '_n_repeats': 1, '_k_per_n_repeat': [1], '_random_state': 3, 'low_memory': False, 'bagged_mode': False, 'max_memory_size': 26017, 'min_memory_size': 26017, 'child_hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'child_hyperparameters_fit': {'ensemble_size': 4}, 'child_ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}}, 'stacker_info': {'num_base_models': 2, 'base_model_names': ['NeuralNetTorch_r30_BAG_L2', 'NeuralNetFastAI_r134_BAG_L2']}, 'children_info': {'S1F1': {'name': 'S1F1', 'model_type': 'GreedyWeightedEnsembleModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.07663822174072266, 'num_classes': 3, 'quantile_levels': None, 'predict_time': None, 'val_score': None, 'hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'hyperparameters_fit': {'ensemble_size': 4}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 6, 'features': ['NeuralNetTorch_r30_BAG_L2_0', 'NeuralNetTorch_r30_BAG_L2_1', 'NeuralNetTorch_r30_BAG_L2_2', 'NeuralNetFastAI_r134_BAG_L2_0', 'NeuralNetFastAI_r134_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_2'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x00000199481A7690>, 'memory_size': 7343, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'model_weights': {'NeuralNetTorch_r30_BAG_L2': 0.25, 'NeuralNetFastAI_r134_BAG_L2': 0.75}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model hyperparameters saved to WeightedEnsemble_L3_hyperparams.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Save model details to a JSON File\n",
    "# ==========================\n",
    "# Store hyperparameters in a structured JSON file for further analysis.\n",
    "json_filename = f\"{model_name}_hyperparams.json\"\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(best_model_hyperparameters, f, indent=4)\n",
    "\n",
    "print(f\"Model hyperparameters saved to {json_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model summary:\n",
      "                          model  score_val eval_metric  pred_time_val  \\\n",
      "0           WeightedEnsemble_L3   0.885417    accuracy       3.396184   \n",
      "1   NeuralNetFastAI_r134_BAG_L2   0.881250    accuracy       3.219157   \n",
      "2   NeuralNetFastAI_r187_BAG_L2   0.879167    accuracy       3.219671   \n",
      "3    NeuralNetFastAI_r65_BAG_L2   0.877083    accuracy       3.217616   \n",
      "4   NeuralNetFastAI_r100_BAG_L2   0.877083    accuracy       3.234588   \n",
      "..                          ...        ...         ...            ...   \n",
      "85  NeuralNetFastAI_r191_BAG_L1   0.789583    accuracy       0.085309   \n",
      "86  NeuralNetFastAI_r111_BAG_L1   0.785417    accuracy       0.094197   \n",
      "87  NeuralNetFastAI_r160_BAG_L1   0.783333    accuracy       0.085326   \n",
      "88  NeuralNetFastAI_r100_BAG_L1   0.779167    accuracy       0.091905   \n",
      "89  NeuralNetFastAI_r194_BAG_L1   0.775000    accuracy       0.078973   \n",
      "\n",
      "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   1517.443671                0.001003           0.076638            3   \n",
      "1   1476.470710                0.093975          34.050183            2   \n",
      "2   1471.740649                0.094489          29.320122            2   \n",
      "3   1471.283671                0.092434          28.863143            2   \n",
      "4   1478.234061                0.109406          35.813534            2   \n",
      "..          ...                     ...                ...          ...   \n",
      "85    19.224029                0.085309          19.224029            1   \n",
      "86    26.329521                0.094197          26.329521            1   \n",
      "87    19.773329                0.085326          19.773329            1   \n",
      "88    37.023017                0.091905          37.023017            1   \n",
      "89    18.156120                0.078973          18.156120            1   \n",
      "\n",
      "    can_infer  fit_order  ...  \\\n",
      "0        True         90  ...   \n",
      "1        True         65  ...   \n",
      "2        True         86  ...   \n",
      "3        True         69  ...   \n",
      "4        True         85  ...   \n",
      "..        ...        ...  ...   \n",
      "85       True          4  ...   \n",
      "86       True         22  ...   \n",
      "87       True         29  ...   \n",
      "88       True         40  ...   \n",
      "89       True         36  ...   \n",
      "\n",
      "                                                                                               hyperparameters  \\\n",
      "0   {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "1    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "2    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "3    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "4    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "..                                                                                                         ...   \n",
      "85   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "86   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "87   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "88   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "89   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "\n",
      "    hyperparameters_fit  \\\n",
      "0                    {}   \n",
      "1                    {}   \n",
      "2                    {}   \n",
      "3                    {}   \n",
      "4                    {}   \n",
      "..                  ...   \n",
      "85                   {}   \n",
      "86                   {}   \n",
      "87                   {}   \n",
      "88                   {}   \n",
      "89                   {}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                            ag_args_fit  \\\n",
      "0   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
      "85  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "86  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "87  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "88  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "89  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   features  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                      [NeuralNetTorch_r30_BAG_L2_1, NeuralNetFastAI_r134_BAG_L2_2, NeuralNetTorch_r30_BAG_L2_2, NeuralNetFastAI_r134_BAG_L2_1, NeuralNetTorch_r30_BAG_L2_0, NeuralNetFastAI_r134_BAG_L2_0]   \n",
      "1   [NeuralNetTorch_r135_BAG_L1_2, NeuralNetTorch_r89_BAG_L1_0, NeuralNetTorch_r22_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_2, NeuralNetTorch_r71_BAG_L1_1, NeuralNetFastAI_r134_BAG_L1_2, gender, NeuralNetFastAI_r102_BAG_L1_0, NeuralNetTorch_r121_BAG_L1_1, NeuralNetTorch_r121_BAG_L1_0, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetFastAI_r69_BAG_L1_1, Discussion, NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r172_BAG_L1_0, NeuralNetTorch_r135_BAG_L1_1, NeuralNetTorch_r76_BAG_L1_2, NeuralNetFastAI_r172_BAG_L1_2, NeuralNetFastAI_r88_BAG_L1_0, NeuralNetFastAI_r102_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_0, Neura...   \n",
      "2   [NeuralNetTorch_r135_BAG_L1_2, NeuralNetTorch_r89_BAG_L1_0, NeuralNetTorch_r22_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_2, NeuralNetTorch_r71_BAG_L1_1, NeuralNetFastAI_r134_BAG_L1_2, gender, NeuralNetFastAI_r102_BAG_L1_0, NeuralNetTorch_r121_BAG_L1_1, NeuralNetTorch_r121_BAG_L1_0, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetFastAI_r69_BAG_L1_1, Discussion, NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r172_BAG_L1_0, NeuralNetTorch_r135_BAG_L1_1, NeuralNetTorch_r76_BAG_L1_2, NeuralNetFastAI_r172_BAG_L1_2, NeuralNetFastAI_r88_BAG_L1_0, NeuralNetFastAI_r102_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_0, Neura...   \n",
      "3   [NeuralNetTorch_r135_BAG_L1_2, NeuralNetTorch_r89_BAG_L1_0, NeuralNetTorch_r22_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_2, NeuralNetTorch_r71_BAG_L1_1, NeuralNetFastAI_r134_BAG_L1_2, gender, NeuralNetFastAI_r102_BAG_L1_0, NeuralNetTorch_r121_BAG_L1_1, NeuralNetTorch_r121_BAG_L1_0, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetFastAI_r69_BAG_L1_1, Discussion, NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r172_BAG_L1_0, NeuralNetTorch_r135_BAG_L1_1, NeuralNetTorch_r76_BAG_L1_2, NeuralNetFastAI_r172_BAG_L1_2, NeuralNetFastAI_r88_BAG_L1_0, NeuralNetFastAI_r102_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_0, Neura...   \n",
      "4   [NeuralNetTorch_r135_BAG_L1_2, NeuralNetTorch_r89_BAG_L1_0, NeuralNetTorch_r22_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_2, NeuralNetTorch_r71_BAG_L1_1, NeuralNetFastAI_r134_BAG_L1_2, gender, NeuralNetFastAI_r102_BAG_L1_0, NeuralNetTorch_r121_BAG_L1_1, NeuralNetTorch_r121_BAG_L1_0, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetFastAI_r69_BAG_L1_1, Discussion, NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r172_BAG_L1_0, NeuralNetTorch_r135_BAG_L1_1, NeuralNetTorch_r76_BAG_L1_2, NeuralNetFastAI_r172_BAG_L1_2, NeuralNetFastAI_r88_BAG_L1_0, NeuralNetFastAI_r102_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_0, Neura...   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
      "85                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "86                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "87                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "88                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "89                                                                                                                                                                                                                                                                                                                                                                                           [Topic, StageID, ParentAnsweringSurvey, Semester, raisedhands, VisITedResources, AnnouncementsView, ParentschoolSatisfaction, GradeID, SectionID, Discussion, StudentAbsenceDays, Relation, gender, PlaceofBirth, NationalITy]   \n",
      "\n",
      "    compile_time  \\\n",
      "0           None   \n",
      "1           None   \n",
      "2           None   \n",
      "3           None   \n",
      "4           None   \n",
      "..           ...   \n",
      "85          None   \n",
      "86          None   \n",
      "87          None   \n",
      "88          None   \n",
      "89          None   \n",
      "\n",
      "                                                                                                                                                                                                               child_hyperparameters  \\\n",
      "0                                                                                                                                                                                   {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
      "1       {'layers': [800, 400], 'emb_drop': 0.006251885504130949, 'ps': 0.2677080696008348, 'bs': 2048, 'lr': 0.01329622020483052, 'epochs': 47, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "2   {'layers': [200, 100, 50], 'emb_drop': 0.5074958658302495, 'ps': 0.34814978753283593, 'bs': 1024, 'lr': 0.026342427824862867, 'epochs': 42, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "3           {'layers': [400], 'emb_drop': 0.22771721361129746, 'ps': 0.3734259772256502, 'bs': 1024, 'lr': 0.0005383511954451698, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "4      {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "..                                                                                                                                                                                                                               ...   \n",
      "85        {'layers': [800, 400], 'emb_drop': 0.5411770367537934, 'ps': 0.23782946566604385, 'bs': 256, 'lr': 0.01519848858318159, 'epochs': 43, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "86       {'layers': [400, 200], 'emb_drop': 0.6343202884164582, 'ps': 0.48362560779595565, 'bs': 2048, 'lr': 0.08479209380262258, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "87    {'layers': [400, 200, 100], 'emb_drop': 0.3171659718142149, 'ps': 0.5909644730871169, 'bs': 128, 'lr': 0.03087210106068273, 'epochs': 20, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "88     {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "89   {'layers': [400, 200, 100], 'emb_drop': 0.5117456464220826, 'ps': 0.2747013981281539, 'bs': 256, 'lr': 0.007212882302137526, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "\n",
      "           child_hyperparameters_fit  \\\n",
      "0               {'ensemble_size': 4}   \n",
      "1    {'epochs': 47, 'best_epoch': 6}   \n",
      "2    {'epochs': 42, 'best_epoch': 4}   \n",
      "3    {'epochs': 38, 'best_epoch': 8}   \n",
      "4    {'epochs': 38, 'best_epoch': 7}   \n",
      "..                               ...   \n",
      "85  {'epochs': 43, 'best_epoch': 14}   \n",
      "86   {'epochs': 21, 'best_epoch': 9}   \n",
      "87   {'epochs': 20, 'best_epoch': 7}   \n",
      "88  {'epochs': 38, 'best_epoch': 16}   \n",
      "89   {'epochs': 21, 'best_epoch': 9}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                              child_ag_args_fit  \\\n",
      "0                                           {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
      "85  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "86  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "87  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "88  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "89  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ancestors  \\\n",
      "0   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r30_BAG_L2, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetFastAI_r134_BAG_L2, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFast...   \n",
      "1   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r194_BAG_L1, NeuralNetTo...   \n",
      "2   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r194_BAG_L1, NeuralNetTo...   \n",
      "3   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r194_BAG_L1, NeuralNetTo...   \n",
      "4   [NeuralNetFastAI_r88_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r111_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r71_BAG_L1, NeuralNetTorch_BAG_L1, NeuralNetTorch_r79_BAG_L1, NeuralNetFastAI_r65_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r145_BAG_L1, NeuralNetTorch_r87_BAG_L1, NeuralNetTorch_r22_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetTorch_r14_BAG_L1, NeuralNetTorch_r19_BAG_L1, NeuralNetFastAI_r187_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r194_BAG_L1, NeuralNetTo...   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
      "85                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "86                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "87                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "88                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "89                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                descendants  \n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [WeightedEnsemble_L3]  \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...  \n",
      "85  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "86  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "87  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "88  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "89  [NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetTorch_r30_BAG_L2, NeuralNetFastAI_r156_BAG_L2, NeuralNetTorch_r79_BAG_L2, NeuralNetTorch_r143_BAG_L2, NeuralNetFastAI_r65_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r14_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetTorch_r19_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetFastAI_r4_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetFastAI_r88_BAG_L2, NeuralNetFastAI_r172_BAG_L2, NeuralNetFastAI_r103_BAG_L2, NeuralNetTorch_r71_BAG_L2, NeuralNetFastAI_...  \n",
      "\n",
      "[90 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Retrieve full model summary\n",
    "# ==========================\n",
    "# Display a leaderboard with all trained models, including:\n",
    "# - Train time\n",
    "# - Validation accuracy\n",
    "# - Performance metrics\n",
    "summary = predictor.leaderboard(extra_info=True)\n",
    "print(\"Full model summary:\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
