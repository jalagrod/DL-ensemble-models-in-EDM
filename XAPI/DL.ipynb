{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda create -n ag python=3.10\n",
    "#!conda activate ag\n",
    "#!conda install -c conda-forge mamba\n",
    "#!mamba install -c conda-forge -c pytorch -c nvidia autogluon \"pytorch=*=*cuda*\"\n",
    "#!mamba install -c conda-forge \"ray-tune >=2.6.3,<2.7\" \"ray-default >=2.6.3,<2.7\"  # install ray for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting autogluon\n",
      "  Using cached autogluon-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.2 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.features==1.2 (from autogluon)\n",
      "  Using cached autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting autogluon.multimodal==1.2 (from autogluon)\n",
      "  Using cached autogluon.multimodal-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.timeseries==1.2 (from autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached autogluon.timeseries-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.16,>=1.5.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn<1.5.3,>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.2)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.2.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.2)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.66.4)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.32.2)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.8.4)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading boto3-1.36.21-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached ray-2.39.0-cp312-cp312-win_amd64.whl.metadata (18 kB)\n",
      "Collecting pyarrow>=15.0.0 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: Pillow<12,>=10.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (10.3.0)\n",
      "Requirement already satisfied: torch<2.6,>=2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (2.3.1+cu121)\n",
      "Collecting lightning<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting transformers<5,>=4.38.0 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting accelerate<1.0,>=0.34.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: jsonschema<4.22,>=4.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (4.19.2)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: torchvision<0.21.0,>=0.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.18.1+cu121)\n",
      "Requirement already satisfied: scikit-image<0.25.0,>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.23.2)\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (1.3)\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: nltk<3.9,>=3.4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (3.8.1)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.7.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (3.1.4)\n",
      "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached nvidia_ml_py3-7.352.0-py3-none-any.whl\n",
      "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting spacy<3.8 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached spacy-3.7.5-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting lightgbm<4.6,>=4.0 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Collecting einops<0.9,>=0.7 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting xgboost<2.2,>=1.6 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached fastai-2.7.18-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting huggingface-hub[torch] (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.2)\n",
      "Collecting pytorch-lightning (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached gluonts-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting statsforecast<1.8,>=1.7.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached statsforecast-1.7.8-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting mlforecast==0.13.4 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached mlforecast-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting utilsforecast<0.2.5,>=0.2.3 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached utilsforecast-0.2.4-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting coreforecast==0.0.12 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached coreforecast-0.0.12-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (5.9.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.2.1)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2024.3.1)\n",
      "Requirement already satisfied: numba in c:\\programdata\\anaconda3\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.59.1)\n",
      "Collecting optuna (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (23.2)\n",
      "Collecting window-ops (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (6.0.1)\n",
      "Collecting safetensors>=0.4.3 (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting botocore<1.37.0,>=1.36.21 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading botocore-1.36.21-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.0.1)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (1.16.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: dill in c:\\programdata\\anaconda3\\lib\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon) (0.3.8)\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pip in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (24.0)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastcore-1.7.29-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.5.3)\n",
      "Requirement already satisfied: toolz~=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.11.0)\n",
      "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.2->autogluon) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.10.6)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.9.0.post0)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (2023.10.3)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.4.6)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (13.3.5)\n",
      "Requirement already satisfied: tabulate in c:\\programdata\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2023.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.13.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.0.3)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.20.3)\n",
      "Requirement already satisfied: aiosignal in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: frozenlist in c:\\programdata\\anaconda3\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.4.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.9.5)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached py_spy-0.4.0-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.14.1)\n",
      "Requirement already satisfied: smart-open in c:\\programdata\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.2.1)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.7.4)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2023.4.12)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached thinc-8.2.5-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (70.3.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.14.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.0.3)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.12)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (2021.4.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5,>=4.38.0->transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.9.3)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (4.12.3)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\programdata\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\programdata\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (2021.11.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.42.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.14.6)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.13.2->statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.5.6)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached blis-0.7.11-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.15.1)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.10.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\programdata\\anaconda3\\lib\\site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (305.1)\n",
      "Collecting alembic>=1.5.0 (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.0.30)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (8.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.3.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Using cached marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (2.5)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.4)\n",
      "Collecting filelock (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached oss2-2.17.0.tar.gz (259 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting packaging (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (1.7.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.4.8)\n",
      "Using cached autogluon-1.2-py3-none-any.whl (9.6 kB)\n",
      "Using cached autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
      "Using cached autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
      "Using cached autogluon.multimodal-1.2-py3-none-any.whl (429 kB)\n",
      "Using cached autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
      "Using cached autogluon.timeseries-1.2-py3-none-any.whl (174 kB)\n",
      "Using cached autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
      "Using cached coreforecast-0.0.12-py3-none-win_amd64.whl (101 kB)\n",
      "Using cached mlforecast-0.13.4-py3-none-any.whl (70 kB)\n",
      "Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Downloading boto3-1.36.21-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.2/139.2 kB 4.2 MB/s eta 0:00:00\n",
      "Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl (101.7 MB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.4/64.4 kB 3.4 MB/s eta 0:00:00\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Using cached fastai-2.7.18-py3-none-any.whl (234 kB)\n",
      "Using cached fugue-0.9.1-py3-none-any.whl (278 kB)\n",
      "Using cached gluonts-0.16.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "Using cached lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
      "Using cached nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "Using cached omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "Using cached openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 7.7 MB/s eta 0:00:00\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/25.2 MB 12.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.3/25.2 MB 13.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.3/25.2 MB 15.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.2/25.2 MB 18.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.2/25.2 MB 18.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.2/25.2 MB 22.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 8.9/25.2 MB 27.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.2/25.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.7/25.2 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.7/25.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.9/25.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 46.7 MB/s eta 0:00:00\n",
      "Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Using cached pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
      "Using cached ray-2.39.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "Using cached spacy-3.7.5-cp312-cp312-win_amd64.whl (11.7 MB)\n",
      "Using cached statsforecast-1.7.8-cp312-cp312-win_amd64.whl (255 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.0/5.5 MB 43.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 58.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 49.9 MB/s eta 0:00:00\n",
      "Using cached timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "Using cached torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 3.4/9.7 MB 72.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.0/9.7 MB 74.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 77.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 61.5 MB/s eta 0:00:00\n",
      "Using cached utilsforecast-0.2.4-py3-none-any.whl (40 kB)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.8/124.9 MB 91.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 5.0/124.9 MB 64.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 8.2/124.9 MB 65.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 11.3/124.9 MB 65.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 13.7/124.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 15.6/124.9 MB 59.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 17.7/124.9 MB 54.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 19.8/124.9 MB 46.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 22.1/124.9 MB 46.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 24.5/124.9 MB 46.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 26.9/124.9 MB 46.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 29.2/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 31.6/124.9 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 33.9/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 36.3/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 38.7/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 41.3/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 43.8/124.9 MB 54.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 45.7/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 48.2/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 50.7/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 53.3/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 55.8/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 58.5/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 61.2/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 63.9/124.9 MB 54.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 66.3/124.9 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 68.3/124.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 70.3/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 72.3/124.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 73.7/124.9 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 73.7/124.9 MB 38.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 73.8/124.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 74.4/124.9 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 76.5/124.9 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 78.6/124.9 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 80.7/124.9 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 82.8/124.9 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 82.9/124.9 MB 26.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 83.4/124.9 MB 23.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 84.0/124.9 MB 26.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 84.2/124.9 MB 26.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 85.1/124.9 MB 25.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 86.7/124.9 MB 24.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 88.3/124.9 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 89.9/124.9 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 91.4/124.9 MB 22.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 94.8/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 96.4/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 98.1/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 99.9/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 101.7/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 103.2/124.9 MB 36.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 104.7/124.9 MB 36.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 106.5/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 108.0/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 108.9/124.9 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 110.8/124.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 112.8/124.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 114.9/124.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 116.7/124.9 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 118.5/124.9 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 120.6/124.9 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  122.6/124.9 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.6/124.9 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.9/124.9 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.9/124.9 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.9/124.9 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 27.3 MB/s eta 0:00:00\n",
      "Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached adagio-0.2.6-py3-none-any.whl (19 kB)\n",
      "Downloading botocore-1.36.21-py3-none-any.whl (13.4 MB)\n",
      "   ---------------------------------------- 0.0/13.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/13.4 MB 57.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.9/13.4 MB 50.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/13.4 MB 48.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.2/13.4 MB 47.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.3/13.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.5/13.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.4/13.4 MB 40.9 MB/s eta 0:00:00\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
      "   ---------------------------------------- 0.0/484.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 484.9/484.9 kB 31.6 MB/s eta 0:00:00\n",
      "Downloading fastcore-1.7.29-py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 0.0/84.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 84.2/84.2 kB 4.6 MB/s eta 0:00:00\n",
      "Using cached fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Using cached fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.7/4.3 MB 53.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.0/4.3 MB 50.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 38.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "   ---------------------------------------- 0.0/464.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 464.1/464.1 kB 14.2 MB/s eta 0:00:00\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Using cached preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "Using cached py_spy-0.4.0-py2.py3-none-win_amd64.whl (1.8 MB)\n",
      "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 0.0/84.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 84.2/84.2 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "   ---------------------------------------- 0.0/303.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 303.8/303.8 kB ? eta 0:00:00\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 632.6/632.6 kB 41.5 MB/s eta 0:00:00\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Using cached thinc-8.2.5-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached triad-0.9.8-py3-none-any.whl (62 kB)\n",
      "Using cached typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.1/4.3 MB 68.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 55.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 45.7 MB/s eta 0:00:00\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Using cached model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Using cached opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Using cached opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "   ---------------------------------------- 0.0/383.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 383.6/383.6 kB 24.9 MB/s eta 0:00:00\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "   ---------------------------------------- 0.0/203.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 203.0/203.0 kB 12.9 MB/s eta 0:00:00\n",
      "Using cached window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 233.6/233.6 kB 14.9 MB/s eta 0:00:00\n",
      "Using cached blis-0.7.11-cp312-cp312-win_amd64.whl (6.6 MB)\n",
      "Using cached cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 160.1/160.1 kB 9.4 MB/s eta 0:00:00\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Using cached openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
      "Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Using cached pycryptodome-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "   ---------------------------------------- 0.0/210.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 210.8/210.8 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/165.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 165.0/165.0 kB ? eta 0:00:00\n",
      "Using cached marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.5 MB/s eta 0:00:00\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: sentencepiece, py4j, py-spy, opencensus-context, nvidia-ml-py3, distlib, cymem, antlr4-python3-runtime, xxhash, wasabi, virtualenv, threadpoolctl, tensorboardX, tensorboard-data-server, spacy-loggers, spacy-legacy, shellingham, safetensors, rsa, pytesseract, pycryptodome, pyarrow, proto-plus, pdf2image, orjson, ordered-set, openxlab, omegaconf, murmurhash, multiprocess, marisa-trie, Mako, lightning-utilities, grpcio, graphviz, googleapis-common-protos, future, fs, fastprogress, fastcore, einops, coreforecast, colorlog, colorful, cloudpathlib, catalogue, blis, absl-py, xgboost, window-ops, tensorboard, srsly, preshed, model-index, lightgbm, language-data, hyperopt, huggingface-hub, google-auth, fastdownload, botocore, alembic, utilsforecast, typer, triad, torchmetrics, tokenizers, seqeval, s3transfer, pytorch-metric-learning, optuna, opendatalab, langcodes, google-api-core, gluonts, gdown, confection, catboost, aiohttp-cors, accelerate, weasel, transformers, timm, thinc, ray, pytorch-lightning, openmim, opencensus, nlpaug, mlforecast, datasets, boto3, adagio, spacy, lightning, fugue, evaluate, autogluon.common, statsforecast, fastai, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
      "Successfully installed Mako-1.3.9 absl-py-2.1.0 accelerate-0.34.2 adagio-0.2.6 aiohttp-cors-0.7.0 alembic-1.14.1 antlr4-python3-runtime-4.9.3 autogluon-1.2 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.multimodal-1.2 autogluon.tabular-1.2 autogluon.timeseries-1.2 blis-0.7.11 boto3-1.36.21 botocore-1.36.21 catalogue-2.0.10 catboost-1.2.7 cloudpathlib-0.20.0 colorful-0.5.6 colorlog-6.9.0 confection-0.1.5 coreforecast-0.0.12 cymem-2.0.11 datasets-3.3.0 distlib-0.3.9 einops-0.8.1 evaluate-0.4.3 fastai-2.7.18 fastcore-1.7.29 fastdownload-0.0.7 fastprogress-1.0.3 fs-2.4.16 fugue-0.9.1 future-1.0.0 gdown-5.2.0 gluonts-0.16.0 google-api-core-2.24.1 google-auth-2.38.0 googleapis-common-protos-1.67.0 graphviz-0.20.3 grpcio-1.70.0 huggingface-hub-0.28.1 hyperopt-0.2.7 langcodes-3.5.0 language-data-1.3.0 lightgbm-4.5.0 lightning-2.5.0.post0 lightning-utilities-0.12.0 marisa-trie-1.2.1 mlforecast-0.13.4 model-index-0.1.11 multiprocess-0.70.16 murmurhash-1.0.12 nlpaug-1.1.11 nvidia-ml-py3-7.352.0 omegaconf-2.2.3 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.2.1 ordered-set-4.1.0 orjson-3.10.15 pdf2image-1.17.0 preshed-3.0.9 proto-plus-1.26.0 py-spy-0.4.0 py4j-0.10.9.9 pyarrow-19.0.0 pycryptodome-3.21.0 pytesseract-0.3.10 pytorch-lightning-2.5.0.post0 pytorch-metric-learning-2.3.0 ray-2.39.0 rsa-4.9 s3transfer-0.11.2 safetensors-0.5.2 sentencepiece-0.2.0 seqeval-1.2.2 shellingham-1.5.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 statsforecast-1.7.8 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 thinc-8.2.5 threadpoolctl-3.5.0 timm-1.0.3 tokenizers-0.21.0 torchmetrics-1.2.1 transformers-4.48.3 triad-0.9.8 typer-0.15.1 utilsforecast-0.2.4 virtualenv-20.29.2 wasabi-1.1.3 weasel-0.4.1 window-ops-0.0.15 xgboost-2.1.4 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script virtualenv.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pytesseract.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openxlab.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mako-render.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts futurize.exe and pasteurize.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts py2pyi.exe and replace_wildcards.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mi.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script hyperopt-mongo-worker.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script alembic.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script typer.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script optuna.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script odl.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script gdown.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script weasel.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts ray.exe, rllib.exe, serve.exe and tune.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mim.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script spacy.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fabric.exe and lightning.exe are installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script evaluate-cli.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script configure_accelerate.exe is installed in 'C:\\Users\\JAL\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.36.21 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# %pip install autogluon\n",
    "#!pip install --upgrade numpy pandas scipy\n",
    "#!pip install numpy==1.26.4\n",
    "#!pip install pyJoules\n",
    "#!pip install mxnet-cu110\n",
    "#!pip install jedi\n",
    "#!pip install setuptools\n",
    "#!pip install scikit-learn==1.3.0\n",
    "#!pip install pandas==2.0.0\n",
    "#!pip install fsspec==2023.1.0\n",
    "#!pip install torch==2.0.1+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "#cls\n",
    "# !pip install cudatoolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "print(torch.cuda.device_count())  # Should be > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.4\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          32\n",
      "Memory Avail:       48.56 GB / 63.94 GB (75.9%)\n",
      "Disk Space Avail:   134.88 GB / 464.91 GB (29.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=10, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-02-17 07:36:48,087\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"GPU_1_XAPI_DL_VALIDATION_kfold\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Beginning AutoGluon training ... Time limit = 896s\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m AutoGluon will save models to \"GPU_1_XAPI_DL_VALIDATION_kfold\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Train Data Rows:    426\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Train Data Columns: 16\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Label Column:       Class\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Problem Type:       multiclass\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Train Data Class Count: 3\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tAvailable Memory:                    48836.87 MB\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\t('int', [])    :  4 | ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\t('object', []) : 12 | ['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', ...]\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\t('category', [])  : 6 | ['NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', 'SectionID', ...]\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\t('int', [])       : 4 | ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t\t('int', ['bool']) : 6 | ['gender', 'Semester', 'Relation', 'ParentAnsweringSurvey', 'ParentschoolSatisfaction', ...]\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t16 features in original data used to generate 16 features in processed data.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Excluded models: ['KNN', 'RF', 'XT', 'CAT', 'XGB', 'GBM'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting 44 L1 models ...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 596.89s of the 895.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.7911\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 590.32s of the 888.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8404\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 584.1s of the 882.77s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8216\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 578.09s of the 876.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8146\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 572.47s of the 871.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8286\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 565.84s of the 864.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8357\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 559.17s of the 857.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8122\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 553.62s of the 852.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.838\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 547.63s of the 846.3s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8427\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 541.16s of the 839.82s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8005\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 534.85s of the 833.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.7981\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 529.37s of the 828.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8169\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 524.38s of the 823.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8216\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 516.41s of the 815.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8192\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 509.03s of the 807.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8028\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 503.51s of the 802.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8568\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 497.71s of the 796.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.838\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 491.61s of the 790.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8263\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t6.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 483.26s of the 781.92s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8286\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 478.34s of the 777.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8146\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t9.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 467.13s of the 765.8s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8192\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 459.66s of the 758.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8052\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 453.29s of the 751.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8263\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 447.45s of the 746.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8052\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 440.23s of the 738.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8122\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 432.65s of the 731.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8333\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 427.45s of the 726.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 423.0s of the 721.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8568\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 416.77s of the 715.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8216\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 411.63s of the 710.3s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8122\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 406.28s of the 704.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8075\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 399.55s of the 698.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8099\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 392.7s of the 691.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 388.04s of the 686.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8404\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 381.03s of the 679.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8169\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 374.61s of the 673.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.7817\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 369.56s of the 668.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8263\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 362.81s of the 661.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8075\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 357.94s of the 656.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8169\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 352.3s of the 650.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.7934\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t8.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 341.99s of the 640.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.831\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t6.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 333.94s of the 632.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 329.26s of the 627.93s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8427\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 323.25s of the 621.92s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8286\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 615.41s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_r41_BAG_L1': 0.714, 'NeuralNetTorch_r86_BAG_L1': 0.143, 'NeuralNetTorch_r1_BAG_L1': 0.143}\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8615\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Excluded models: ['KNN', 'RF', 'XT', 'CAT', 'XGB', 'GBM'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting 44 L2 models ...\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 615.33s of the 615.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8662\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 610.42s of the 610.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 604.31s of the 604.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 598.51s of the 598.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 592.7s of the 592.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 586.71s of the 586.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 579.82s of the 579.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 574.04s of the 573.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 567.56s of the 567.5s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 561.92s of the 561.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L2 ... Training model for up to 555.67s of the 555.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8756\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L2 ... Training model for up to 550.42s of the 550.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L2 ... Training model for up to 545.72s of the 545.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r156_BAG_L2 ... Training model for up to 537.65s of the 537.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r95_BAG_L2 ... Training model for up to 530.24s of the 530.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8662\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r41_BAG_L2 ... Training model for up to 524.36s of the 524.3s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.43s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r158_BAG_L2 ... Training model for up to 518.77s of the 518.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r37_BAG_L2 ... Training model for up to 512.62s of the 512.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8803\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t6.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r197_BAG_L2 ... Training model for up to 504.07s of the 504.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r134_BAG_L2 ... Training model for up to 499.07s of the 499.0s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t9.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r143_BAG_L2 ... Training model for up to 487.61s of the 487.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8709\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r111_BAG_L2 ... Training model for up to 480.74s of the 480.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r31_BAG_L2 ... Training model for up to 474.04s of the 473.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r65_BAG_L2 ... Training model for up to 469.11s of the 469.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8709\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r88_BAG_L2 ... Training model for up to 461.45s of the 461.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8803\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r87_BAG_L2 ... Training model for up to 453.4s of the 453.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8826\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r71_BAG_L2 ... Training model for up to 448.18s of the 448.11s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r185_BAG_L2 ... Training model for up to 443.49s of the 443.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8826\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r160_BAG_L2 ... Training model for up to 437.46s of the 437.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8615\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r69_BAG_L2 ... Training model for up to 432.06s of the 432.0s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8638\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r138_BAG_L2 ... Training model for up to 426.67s of the 426.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8803\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.54s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r172_BAG_L2 ... Training model for up to 419.86s of the 419.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r76_BAG_L2 ... Training model for up to 412.99s of the 412.93s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8615\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r121_BAG_L2 ... Training model for up to 408.15s of the 408.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8709\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r127_BAG_L2 ... Training model for up to 401.39s of the 401.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r194_BAG_L2 ... Training model for up to 394.77s of the 394.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8592\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r135_BAG_L2 ... Training model for up to 389.71s of the 389.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t4.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r4_BAG_L2 ... Training model for up to 383.4s of the 383.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r36_BAG_L2 ... Training model for up to 378.39s of the 378.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8803\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r100_BAG_L2 ... Training model for up to 373.3s of the 373.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8779\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t8.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetFastAI_r187_BAG_L2 ... Training model for up to 362.55s of the 362.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t5.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r19_BAG_L2 ... Training model for up to 354.91s of the 354.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8592\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t2.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r1_BAG_L2 ... Training model for up to 350.46s of the 350.4s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8709\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: NeuralNetTorch_r89_BAG_L2 ... Training model for up to 344.32s of the 344.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=3, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.8732\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t3.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 338.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_r87_BAG_L2': 0.95, 'NeuralNetFastAI_r156_BAG_L2': 0.05}\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.885\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m AutoGluon training complete, total runtime = 557.59s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 11.2 rows/s (43 batch size)\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"GPU_1_XAPI_DL_VALIDATION_kfold\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=59344)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     NeuralNetTorch_r14_BAG_L2       0.851852   0.868545    accuracy       10.199735       3.748448  189.521750                 0.267735                0.229954           2.520872            2       True         57\n",
      "1    NeuralNetTorch_r185_BAG_L1       0.833333   0.856808    accuracy        0.167771       0.062519    4.068768                 0.167771                0.062519           4.068768            1       True         28\n",
      "2    NeuralNetFastAI_r88_BAG_L2       0.833333   0.880282    accuracy       10.161119       3.609735  192.891410                 0.229118                0.091241           5.890531            2       True         70\n",
      "3     NeuralNetTorch_r31_BAG_L2       0.833333   0.868545    accuracy       10.208758       3.777671  189.723631                 0.276758                0.259177           2.722753            2       True         68\n",
      "4     NeuralNetTorch_r41_BAG_L2       0.833333   0.877934    accuracy       10.217235       3.752583  190.433926                 0.285234                0.234089           3.433048            2       True         61\n",
      "5     NeuralNetTorch_r89_BAG_L2       0.833333   0.873239    accuracy       10.220525       3.780159  190.912135                 0.288524                0.261665           3.911257            2       True         89\n",
      "6     NeuralNetTorch_r87_BAG_L2       0.833333   0.882629    accuracy       10.229595       3.752285  190.195332                 0.297595                0.233791           3.194453            2       True         71\n",
      "7         NeuralNetTorch_BAG_L2       0.833333   0.868545    accuracy       10.234002       3.751446  190.865608                 0.302001                0.232953           3.864730            2       True         47\n",
      "8           WeightedEnsemble_L3       0.833333   0.884977    accuracy       10.469614       3.854870  195.676113                 0.005001                0.001003           0.074887            3       True         90\n",
      "9     NeuralNetTorch_r71_BAG_L1       0.814815   0.823944    accuracy        0.142565       0.061331    2.394514                 0.142565                0.061331           2.394514            1       True         27\n",
      "10    NeuralNetTorch_r86_BAG_L1       0.814815   0.842723    accuracy        0.168632       0.063392    4.408880                 0.168632                0.063392           4.408880            1       True          9\n",
      "11     NeuralNetTorch_r1_BAG_L1       0.814815   0.842723    accuracy        0.173142       0.069245    3.938250                 0.173142                0.069245           3.938250            1       True         43\n",
      "12   NeuralNetTorch_r121_BAG_L1       0.814815   0.840376    accuracy        0.201542       0.073827    4.911920                 0.201542                0.073827           4.911920            1       True         34\n",
      "13          WeightedEnsemble_L2       0.814815   0.861502    accuracy        0.507514       0.195961   12.013631                 0.007994                0.001000           0.066074            2       True         45\n",
      "14    NeuralNetFastAI_r4_BAG_L2       0.814815   0.873239    accuracy       10.150493       3.602916  189.949491                 0.218493                0.084422           2.948612            2       True         83\n",
      "15  NeuralNetFastAI_r172_BAG_L2       0.814815   0.868545    accuracy       10.164918       3.613287  191.796749                 0.232918                0.094793           4.795870            2       True         77\n",
      "16   NeuralNetFastAI_r37_BAG_L2       0.814815   0.880282    accuracy       10.201979       3.635721  193.514605                 0.269978                0.117227           6.513726            2       True         63\n",
      "17    NeuralNetTorch_r76_BAG_L2       0.814815   0.861502    accuracy       10.203782       3.755002  189.520706                 0.271782                0.236509           2.519828            2       True         78\n",
      "18    NeuralNetTorch_r19_BAG_L2       0.814815   0.859155    accuracy       10.206175       3.771272  189.463538                 0.274175                0.252779           2.462659            2       True         87\n",
      "19    NeuralNetTorch_r71_BAG_L2       0.814815   0.873239    accuracy       10.220264       3.744614  189.641898                 0.288264                0.226120           2.641019            2       True         72\n",
      "20   NeuralNetTorch_r135_BAG_L2       0.814815   0.877934    accuracy       10.244274       3.756183  191.072275                 0.312274                0.237689           4.071397            2       True         82\n",
      "21   NeuralNetTorch_r197_BAG_L2       0.814815   0.868545    accuracy       10.245370       3.755872  189.881372                 0.313369                0.237378           2.880493            2       True         64\n",
      "22   NeuralNetTorch_r158_BAG_L2       0.814815   0.873239    accuracy       10.250163       3.741311  191.140265                 0.318162                0.222817           4.139387            2       True         62\n",
      "23   NeuralNetTorch_r143_BAG_L2       0.814815   0.870892    accuracy       10.253363       3.774165  191.859579                 0.321362                0.255672           4.858701            2       True         66\n",
      "24    NeuralNetTorch_r22_BAG_L2       0.814815   0.868545    accuracy       10.256890       3.759292  190.874763                 0.324890                0.240798           3.873884            2       True         50\n",
      "25   NeuralNetTorch_r121_BAG_L2       0.814815   0.870892    accuracy       10.281104       3.775080  191.637707                 0.349104                0.256587           4.636829            2       True         79\n",
      "26    NeuralNetTorch_r86_BAG_L2       0.814815   0.873239    accuracy       10.315046       3.745849  190.620898                 0.383045                0.227355           3.620019            2       True         54\n",
      "27    NeuralNetTorch_r14_BAG_L1       0.796296   0.816901    accuracy        0.127314       0.063813    2.622535                 0.127314                0.063813           2.622535            1       True         12\n",
      "28   NeuralNetTorch_r197_BAG_L1       0.796296   0.828638    accuracy        0.139423       0.071671    2.861662                 0.139423                0.071671           2.861662            1       True         19\n",
      "29    NeuralNetTorch_r36_BAG_L1       0.796296   0.816901    accuracy        0.142510       0.066877    3.456546                 0.142510                0.066877           3.456546            1       True         39\n",
      "30    NeuralNetTorch_r41_BAG_L1       0.796296   0.856808    accuracy        0.157747       0.062324    3.600426                 0.157747                0.062324           3.600426            1       True         16\n",
      "31   NeuralNetTorch_r158_BAG_L1       0.796296   0.838028    accuracy        0.172211       0.066709    4.015018                 0.172211                0.066709           4.015018            1       True         17\n",
      "32    NeuralNetTorch_r30_BAG_L1       0.796296   0.838028    accuracy        0.180762       0.070368    3.853073                 0.180762                0.070368           3.853073            1       True          8\n",
      "33  NeuralNetFastAI_r160_BAG_L2       0.796296   0.861502    accuracy       10.149158       3.604861  190.302166                 0.217157                0.086368           3.301287            2       True         74\n",
      "34   NeuralNetFastAI_r69_BAG_L2       0.796296   0.863850    accuracy       10.153462       3.596305  190.186703                 0.221462                0.077812           3.185825            2       True         75\n",
      "35  NeuralNetFastAI_r194_BAG_L2       0.796296   0.859155    accuracy       10.164298       3.606831  189.915714                 0.232297                0.088337           2.914836            2       True         81\n",
      "36  NeuralNetFastAI_r145_BAG_L2       0.796296   0.873239    accuracy       10.168203       3.608617  190.593683                 0.236202                0.090123           3.592804            2       True         52\n",
      "37   NeuralNetFastAI_r65_BAG_L2       0.796296   0.870892    accuracy       10.173656       3.610077  192.507679                 0.241656                0.091584           5.506800            2       True         69\n",
      "38  NeuralNetFastAI_r102_BAG_L2       0.796296   0.875587    accuracy       10.175485       3.622229  191.879216                 0.243484                0.103735           4.878338            2       True         51\n",
      "39  NeuralNetFastAI_r143_BAG_L2       0.796296   0.877934    accuracy       10.176209       3.624492  192.940612                 0.244209                0.105998           5.939734            2       True         58\n",
      "40  NeuralNetFastAI_r134_BAG_L2       0.796296   0.868545    accuracy       10.176967       3.657699  196.340519                 0.244967                0.139205           9.339641            2       True         65\n",
      "41  NeuralNetFastAI_r127_BAG_L2       0.796296   0.873239    accuracy       10.192790       3.619694  191.637851                 0.260789                0.101201           4.636972            2       True         80\n",
      "42     NeuralNetTorch_r1_BAG_L2       0.796296   0.870892    accuracy       10.193686       3.766850  190.966198                 0.261685                0.248356           3.965320            2       True         88\n",
      "43  NeuralNetFastAI_r100_BAG_L2       0.796296   0.877934    accuracy       10.197264       3.661485  195.580107                 0.265263                0.142992           8.579229            2       True         85\n",
      "44    NeuralNetTorch_r36_BAG_L2       0.796296   0.880282    accuracy       10.218736       3.765229  189.787067                 0.286736                0.246735           2.786189            2       True         84\n",
      "45   NeuralNetTorch_r185_BAG_L2       0.796296   0.882629    accuracy       10.225382       3.772053  190.908301                 0.293382                0.253560           3.907422            2       True         73\n",
      "46    NeuralNetTorch_r30_BAG_L2       0.796296   0.875587    accuracy       10.249753       3.748361  191.359448                 0.317752                0.229867           4.358570            2       True         53\n",
      "47    NeuralNetTorch_r76_BAG_L1       0.777778   0.823944    accuracy        0.124610       0.060575    2.552758                 0.124610                0.060575           2.552758            1       True         33\n",
      "48    NeuralNetTorch_r19_BAG_L1       0.777778   0.823944    accuracy        0.130544       0.060356    2.647519                 0.130544                0.060356           2.647519            1       True         42\n",
      "49    NeuralNetTorch_r87_BAG_L1       0.777778   0.833333    accuracy        0.151378       0.063685    3.235039                 0.151378                0.063685           3.235039            1       True         26\n",
      "50    NeuralNetTorch_r89_BAG_L1       0.777778   0.828638    accuracy        0.156704       0.061601    4.234116                 0.156704                0.061601           4.234116            1       True         44\n",
      "51        NeuralNetTorch_BAG_L1       0.777778   0.840376    accuracy        0.163138       0.061233    3.974820                 0.163138                0.061233           3.974820            1       True          2\n",
      "52    NeuralNetTorch_r79_BAG_L1       0.777778   0.821596    accuracy        0.166525       0.061196    3.966759                 0.166525                0.061196           3.966759            1       True          3\n",
      "53   NeuralNetTorch_r135_BAG_L1       0.777778   0.826291    accuracy        0.178583       0.067295    4.503392                 0.178583                0.067295           4.503392            1       True         37\n",
      "54    NeuralNetTorch_r22_BAG_L1       0.777778   0.828638    accuracy        0.187408       0.070181    4.504991                 0.187408                0.070181           4.504991            1       True          5\n",
      "55    NeuralNetFastAI_r4_BAG_L1       0.777778   0.807512    accuracy        0.248270       0.070472    2.867927                 0.248270                0.070472           2.867927            1       True         38\n",
      "56  NeuralNetFastAI_r187_BAG_L2       0.777778   0.873239    accuracy       10.174638       3.620532  192.605294                 0.242638                0.102038           5.604416            2       True         86\n",
      "57    NeuralNetTorch_r79_BAG_L2       0.777778   0.873239    accuracy       10.226551       3.737304  190.825433                 0.294550                0.218811           3.824555            2       True         48\n",
      "58    NeuralNetTorch_r31_BAG_L1       0.759259   0.826291    accuracy        0.139893       0.063750    3.693904                 0.139893                0.063750           3.693904            1       True         23\n",
      "59   NeuralNetFastAI_r11_BAG_L1       0.759259   0.800469    accuracy        0.258878       0.110160    4.290730                 0.258878                0.110160           4.290730            1       True         10\n",
      "60  NeuralNetFastAI_r102_BAG_L1       0.759259   0.835681    accuracy        0.271409       0.089291    4.712135                 0.271409                0.089291           4.712135            1       True          6\n",
      "61  NeuralNetFastAI_r103_BAG_L2       0.759259   0.875587    accuracy       10.154688       3.599352  190.156090                 0.222687                0.080858           3.155211            2       True         56\n",
      "62  NeuralNetFastAI_r191_BAG_L2       0.759259   0.875587    accuracy       10.157040       3.620551  190.805230                 0.225040                0.102057           3.804352            2       True         49\n",
      "63       NeuralNetFastAI_BAG_L2       0.759259   0.866197    accuracy       10.158853       3.602483  189.915420                 0.226852                0.083989           2.914542            2       True         46\n",
      "64   NeuralNetFastAI_r11_BAG_L2       0.759259   0.873239    accuracy       10.161511       3.619669  191.239518                 0.229510                0.101175           4.238640            2       True         55\n",
      "65  NeuralNetFastAI_r156_BAG_L2       0.759259   0.877934    accuracy       10.167018       3.620076  192.406773                 0.235018                0.101582           5.405894            2       True         59\n",
      "66  NeuralNetFastAI_r111_BAG_L2       0.759259   0.873239    accuracy       10.170038       3.624097  191.612240                 0.238037                0.105603           4.611361            2       True         67\n",
      "67  NeuralNetFastAI_r138_BAG_L2       0.759259   0.880282    accuracy       10.176212       3.623177  191.537266                 0.244211                0.104683           4.536387            2       True         76\n",
      "68   NeuralNetTorch_r143_BAG_L1       0.740741   0.819249    accuracy        0.190037       0.078606    5.492835                 0.190037                0.078606           5.492835            1       True         21\n",
      "69   NeuralNetFastAI_r95_BAG_L2       0.740741   0.866197    accuracy       10.158240       3.606609  190.818321                 0.226239                0.088115           3.817443            2       True         60\n",
      "70   NeuralNetFastAI_r37_BAG_L1       0.722222   0.826291    accuracy        0.254335       0.096431    6.323017                 0.254335                0.096431           6.323017            1       True         18\n",
      "71   NeuralNetFastAI_r69_BAG_L1       0.703704   0.812207    accuracy        0.254711       0.079436    3.138863                 0.254711                0.079436           3.138863            1       True         30\n",
      "72   NeuralNetFastAI_r88_BAG_L1       0.703704   0.812207    accuracy        0.255596       0.088451    5.443771                 0.255596                0.088451           5.443771            1       True         25\n",
      "73  NeuralNetFastAI_r172_BAG_L1       0.703704   0.809859    accuracy        0.263417       0.086793    4.685945                 0.263417                0.086793           4.685945            1       True         32\n",
      "74  NeuralNetFastAI_r143_BAG_L1       0.703704   0.821596    accuracy        0.266531       0.090565    5.829760                 0.266531                0.090565           5.829760            1       True         13\n",
      "75  NeuralNetFastAI_r160_BAG_L1       0.703704   0.821596    accuracy        0.268483       0.088852    3.167238                 0.268483                0.088852           3.167238            1       True         29\n",
      "76  NeuralNetFastAI_r187_BAG_L1       0.703704   0.830986    accuracy        0.275328       0.092818    6.022861                 0.275328                0.092818           6.022861            1       True         41\n",
      "77  NeuralNetFastAI_r111_BAG_L1       0.703704   0.805164    accuracy        0.276578       0.096396    4.391793                 0.276578                0.096396           4.391793            1       True         22\n",
      "78  NeuralNetFastAI_r134_BAG_L1       0.703704   0.814554    accuracy        0.281206       0.148333    9.185894                 0.281206                0.148333           9.185894            1       True         20\n",
      "79  NeuralNetFastAI_r138_BAG_L1       0.685185   0.807512    accuracy        0.252993       0.086001    4.510466                 0.252993                0.086001           4.510466            1       True         31\n",
      "80  NeuralNetFastAI_r127_BAG_L1       0.685185   0.816901    accuracy        0.257531       0.097013    4.435927                 0.257531                0.097013           4.435927            1       True         35\n",
      "81  NeuralNetFastAI_r191_BAG_L1       0.685185   0.814554    accuracy        0.261099       0.088219    3.642626                 0.261099                0.088219           3.642626            1       True          4\n",
      "82  NeuralNetFastAI_r145_BAG_L1       0.685185   0.812207    accuracy        0.266285       0.080860    3.459137                 0.266285                0.080860           3.459137            1       True          7\n",
      "83  NeuralNetFastAI_r156_BAG_L1       0.685185   0.819249    accuracy        0.266937       0.089641    5.248919                 0.266937                0.089641           5.248919            1       True         14\n",
      "84  NeuralNetFastAI_r194_BAG_L1       0.666667   0.781690    accuracy        0.246564       0.082443    2.866691                 0.246564                0.082443           2.866691            1       True         36\n",
      "85  NeuralNetFastAI_r103_BAG_L1       0.666667   0.798122    accuracy        0.247587       0.079717    3.314225                 0.247587                0.079717           3.314225            1       True         11\n",
      "86       NeuralNetFastAI_BAG_L1       0.666667   0.791080    accuracy        0.810397       0.087632    3.444050                 0.810397                0.087632           3.444050            1       True          1\n",
      "87   NeuralNetFastAI_r95_BAG_L1       0.648148   0.802817    accuracy        0.244226       0.081486    3.532992                 0.244226                0.081486           3.532992            1       True         15\n",
      "88   NeuralNetFastAI_r65_BAG_L1       0.648148   0.805164    accuracy        0.274733       0.097146    5.234411                 0.274733                0.097146           5.234411            1       True         24\n",
      "89  NeuralNetFastAI_r100_BAG_L1       0.629630   0.793427    accuracy        0.266467       0.129784    8.313776                 0.266467                0.129784           8.313776            1       True         40\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t586s\t = DyStack   runtime |\t3014s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3014s\n",
      "AutoGluon will save models to \"GPU_1_XAPI_DL_VALIDATION_kfold\"\n",
      "Train Data Rows:    480\n",
      "Train Data Columns: 16\n",
      "Label Column:       Class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    48308.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    :  4 | ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']\n",
      "\t\t('object', []) : 12 | ['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', 'SectionID', ...]\n",
      "\t\t('int', [])       : 4 | ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']\n",
      "\t\t('int', ['bool']) : 6 | ['gender', 'Semester', 'Relation', 'ParentAnsweringSurvey', 'ParentschoolSatisfaction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['GBM', 'RF', 'KNN', 'XT', 'XGB', 'CAT'] (Specified by `excluded_model_types`)\n",
      "Fitting 44 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2008.9s of the 3014.1s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7979\t = Validation score   (accuracy)\n",
      "\t17.94s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1989.33s of the 2994.53s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8208\t = Validation score   (accuracy)\n",
      "\t38.93s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1948.73s of the 2953.93s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8229\t = Validation score   (accuracy)\n",
      "\t38.67s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1908.45s of the 2913.65s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7896\t = Validation score   (accuracy)\n",
      "\t18.84s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1888.01s of the 2893.21s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8\t = Validation score   (accuracy)\n",
      "\t40.44s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1845.98s of the 2851.18s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t27.0s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1817.34s of the 2822.54s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8042\t = Validation score   (accuracy)\n",
      "\t20.15s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1795.56s of the 2800.76s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8167\t = Validation score   (accuracy)\n",
      "\t45.79s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1748.14s of the 2753.34s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8417\t = Validation score   (accuracy)\n",
      "\t38.35s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 1708.14s of the 2713.34s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8062\t = Validation score   (accuracy)\n",
      "\t21.27s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 1685.27s of the 2690.47s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7896\t = Validation score   (accuracy)\n",
      "\t17.74s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 1665.89s of the 2671.09s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8354\t = Validation score   (accuracy)\n",
      "\t31.99s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 1632.31s of the 2637.51s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7958\t = Validation score   (accuracy)\n",
      "\t29.42s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 1601.29s of the 2606.49s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t28.16s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 1571.48s of the 2576.68s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8042\t = Validation score   (accuracy)\n",
      "\t20.06s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 1549.73s of the 2554.93s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8292\t = Validation score   (accuracy)\n",
      "\t36.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 1511.58s of the 2516.78s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8208\t = Validation score   (accuracy)\n",
      "\t42.73s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 1467.24s of the 2472.44s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t32.34s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 1433.27s of the 2438.47s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.825\t = Validation score   (accuracy)\n",
      "\t33.25s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 1398.33s of the 2403.53s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8208\t = Validation score   (accuracy)\n",
      "\t39.14s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 1357.57s of the 2362.77s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8271\t = Validation score   (accuracy)\n",
      "\t55.86s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 1300.12s of the 2305.32s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7854\t = Validation score   (accuracy)\n",
      "\t25.08s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 1273.42s of the 2278.62s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t35.18s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 1236.6s of the 2241.8s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8021\t = Validation score   (accuracy)\n",
      "\t29.45s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 1205.56s of the 2210.76s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8042\t = Validation score   (accuracy)\n",
      "\t27.08s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 1176.8s of the 2182.0s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8292\t = Validation score   (accuracy)\n",
      "\t37.0s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 1138.25s of the 2143.45s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8396\t = Validation score   (accuracy)\n",
      "\t30.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 1106.05s of the 2111.25s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t41.31s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 1063.19s of the 2068.39s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7833\t = Validation score   (accuracy)\n",
      "\t18.86s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 1042.7s of the 2047.9s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t18.86s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 1022.11s of the 2027.31s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8021\t = Validation score   (accuracy)\n",
      "\t22.62s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 997.76s of the 2002.96s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8125\t = Validation score   (accuracy)\n",
      "\t26.88s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 969.24s of the 1974.44s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8562\t = Validation score   (accuracy)\n",
      "\t33.31s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 934.33s of the 1939.53s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8396\t = Validation score   (accuracy)\n",
      "\t42.42s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 890.35s of the 1895.55s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8146\t = Validation score   (accuracy)\n",
      "\t26.33s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 862.39s of the 1867.59s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.775\t = Validation score   (accuracy)\n",
      "\t17.57s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 843.17s of the 1848.37s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8354\t = Validation score   (accuracy)\n",
      "\t45.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 795.71s of the 1800.91s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8062\t = Validation score   (accuracy)\n",
      "\t17.82s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 776.27s of the 1781.47s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8083\t = Validation score   (accuracy)\n",
      "\t35.68s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 738.92s of the 1744.12s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.7792\t = Validation score   (accuracy)\n",
      "\t35.6s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 701.68s of the 1706.88s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8062\t = Validation score   (accuracy)\n",
      "\t29.42s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 670.55s of the 1675.75s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8375\t = Validation score   (accuracy)\n",
      "\t32.4s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 636.59s of the 1641.79s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8333\t = Validation score   (accuracy)\n",
      "\t40.44s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 594.59s of the 1599.79s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8375\t = Validation score   (accuracy)\n",
      "\t41.22s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1556.81s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r76_BAG_L1': 0.5, 'NeuralNetTorch_r86_BAG_L1': 0.167, 'NeuralNetFastAI_r156_BAG_L1': 0.167, 'NeuralNetTorch_r185_BAG_L1': 0.083, 'NeuralNetTorch_r121_BAG_L1': 0.083}\n",
      "\t0.8646\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['GBM', 'RF', 'KNN', 'XT', 'XGB', 'CAT'] (Specified by `excluded_model_types`)\n",
      "Fitting 44 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1556.73s of the 1556.65s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8646\t = Validation score   (accuracy)\n",
      "\t17.59s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1537.51s of the 1537.43s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t33.86s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 1501.93s of the 1501.86s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t39.32s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 1460.96s of the 1460.9s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t19.07s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 1440.25s of the 1440.18s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8667\t = Validation score   (accuracy)\n",
      "\t37.46s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 1401.09s of the 1401.02s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8625\t = Validation score   (accuracy)\n",
      "\t27.46s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 1371.92s of the 1371.85s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t20.75s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 1349.47s of the 1349.39s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8771\t = Validation score   (accuracy)\n",
      "\t40.61s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 1307.17s of the 1307.11s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t35.06s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 1270.52s of the 1270.46s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t21.53s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L2 ... Training model for up to 1247.25s of the 1247.18s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8562\t = Validation score   (accuracy)\n",
      "\t18.12s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L2 ... Training model for up to 1227.47s of the 1227.4s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t30.81s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L2 ... Training model for up to 1195.03s of the 1194.96s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t28.25s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L2 ... Training model for up to 1165.09s of the 1165.02s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t26.54s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L2 ... Training model for up to 1136.85s of the 1136.78s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t20.49s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L2 ... Training model for up to 1114.57s of the 1114.5s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8625\t = Validation score   (accuracy)\n",
      "\t34.59s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L2 ... Training model for up to 1078.33s of the 1078.26s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t39.8s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L2 ... Training model for up to 1036.93s of the 1036.87s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t28.33s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L2 ... Training model for up to 1006.95s of the 1006.88s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8583\t = Validation score   (accuracy)\n",
      "\t30.62s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L2 ... Training model for up to 974.63s of the 974.57s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8812\t = Validation score   (accuracy)\n",
      "\t33.04s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L2 ... Training model for up to 939.96s of the 939.89s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t44.01s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L2 ... Training model for up to 894.36s of the 894.29s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t26.55s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L2 ... Training model for up to 866.06s of the 865.99s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8646\t = Validation score   (accuracy)\n",
      "\t33.36s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L2 ... Training model for up to 831.01s of the 830.94s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8771\t = Validation score   (accuracy)\n",
      "\t28.42s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L2 ... Training model for up to 800.88s of the 800.81s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t27.89s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L2 ... Training model for up to 771.32s of the 771.26s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t34.9s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L2 ... Training model for up to 734.73s of the 734.66s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8562\t = Validation score   (accuracy)\n",
      "\t31.1s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L2 ... Training model for up to 701.98s of the 701.92s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8667\t = Validation score   (accuracy)\n",
      "\t36.39s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L2 ... Training model for up to 663.97s of the 663.91s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t19.48s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L2 ... Training model for up to 642.84s of the 642.77s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t19.17s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L2 ... Training model for up to 621.96s of the 621.89s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t22.54s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L2 ... Training model for up to 597.67s of the 597.6s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8667\t = Validation score   (accuracy)\n",
      "\t27.3s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L2 ... Training model for up to 568.68s of the 568.61s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t31.9s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L2 ... Training model for up to 534.96s of the 534.89s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t38.52s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L2 ... Training model for up to 494.83s of the 494.76s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8604\t = Validation score   (accuracy)\n",
      "\t27.18s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L2 ... Training model for up to 466.02s of the 465.96s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8625\t = Validation score   (accuracy)\n",
      "\t18.19s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L2 ... Training model for up to 446.12s of the 446.05s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8708\t = Validation score   (accuracy)\n",
      "\t42.1s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L2 ... Training model for up to 402.31s of the 402.23s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t18.14s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L2 ... Training model for up to 382.47s of the 382.4s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t34.07s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L2 ... Training model for up to 346.74s of the 346.67s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8771\t = Validation score   (accuracy)\n",
      "\t35.6s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L2 ... Training model for up to 309.42s of the 309.35s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=16, gpus=0, memory=0.01%)\n",
      "\t0.8792\t = Validation score   (accuracy)\n",
      "\t29.12s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L2 ... Training model for up to 278.52s of the 278.46s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t31.83s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L2 ... Training model for up to 245.05s of the 244.98s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t37.81s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L2 ... Training model for up to 205.57s of the 205.5s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=0.00%)\n",
      "\t0.8583\t = Validation score   (accuracy)\n",
      "\t37.07s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 166.53s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_r134_BAG_L2': 0.75, 'NeuralNetTorch_r30_BAG_L2': 0.25}\n",
      "\t0.8854\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2847.76s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 14.6 rows/s (48 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"GPU_1_XAPI_DL_VALIDATION_kfold\")\n",
      "C:\\Users\\JAL\\AppData\\Local\\Temp\\ipykernel_600\\1411719846.py:63: DeprecationWarning: `get_oof_pred` has been deprecated and will be removed in version 1.2. Please use `predict_oof` instead. This will raise an error in the future!\n",
      "  oof_pred = predictor.get_oof_pred()\n",
      "C:\\Users\\JAL\\AppData\\Local\\Temp\\ipykernel_600\\1411719846.py:76: DeprecationWarning: `get_oof_pred_proba` has been deprecated and will be removed in version 1.2. Please use `predict_proba_oof` instead. This will raise an error in the future!\n",
      "  proba_oof = predictor.get_oof_pred_proba()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Metrics saved to: GPU_1_XAPI_OOF_RESULTS_kfold_59.29.csv\n",
      "Final Metrics saved to: GPU_1_XAPI_FINAL_RESULTS_kfold_59.29.csv\n",
      "CV Scores summary:                           model  score_val eval_metric  pred_time_val  \\\n",
      "0           WeightedEnsemble_L3   0.885417    accuracy       3.295865   \n",
      "1   NeuralNetFastAI_r134_BAG_L2   0.881250    accuracy       3.119995   \n",
      "2   NeuralNetFastAI_r187_BAG_L2   0.879167    accuracy       3.132973   \n",
      "3    NeuralNetFastAI_r65_BAG_L2   0.877083    accuracy       3.126476   \n",
      "4   NeuralNetFastAI_r100_BAG_L2   0.877083    accuracy       3.128721   \n",
      "..                          ...        ...         ...            ...   \n",
      "85  NeuralNetFastAI_r191_BAG_L1   0.789583    accuracy       0.075795   \n",
      "86  NeuralNetFastAI_r111_BAG_L1   0.785417    accuracy       0.094508   \n",
      "87  NeuralNetFastAI_r160_BAG_L1   0.783333    accuracy       0.078439   \n",
      "88  NeuralNetFastAI_r100_BAG_L1   0.779167    accuracy       0.094456   \n",
      "89  NeuralNetFastAI_r194_BAG_L1   0.775000    accuracy       0.078996   \n",
      "\n",
      "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   1459.200022                0.000000           0.073460            3   \n",
      "1   1418.518621                0.091960          33.040642            2   \n",
      "2   1414.599989                0.104939          29.122010            2   \n",
      "3   1413.897557                0.098441          28.419578            2   \n",
      "4   1421.082728                0.100686          35.604748            2   \n",
      "..          ...                     ...                ...          ...   \n",
      "85    18.835353                0.075795          18.835353            1   \n",
      "86    25.075900                0.094508          25.075900            1   \n",
      "87    18.860267                0.078439          18.860267            1   \n",
      "88    35.602620                0.094456          35.602620            1   \n",
      "89    17.569243                0.078996          17.569243            1   \n",
      "\n",
      "    can_infer  fit_order  ...  \\\n",
      "0        True         90  ...   \n",
      "1        True         65  ...   \n",
      "2        True         86  ...   \n",
      "3        True         69  ...   \n",
      "4        True         85  ...   \n",
      "..        ...        ...  ...   \n",
      "85       True          4  ...   \n",
      "86       True         22  ...   \n",
      "87       True         29  ...   \n",
      "88       True         40  ...   \n",
      "89       True         36  ...   \n",
      "\n",
      "                                                                                               hyperparameters  \\\n",
      "0   {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "1    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "2    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "3    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "4    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "..                                                                                                         ...   \n",
      "85   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "86   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "87   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "88   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "89   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "\n",
      "    hyperparameters_fit  \\\n",
      "0                    {}   \n",
      "1                    {}   \n",
      "2                    {}   \n",
      "3                    {}   \n",
      "4                    {}   \n",
      "..                  ...   \n",
      "85                   {}   \n",
      "86                   {}   \n",
      "87                   {}   \n",
      "88                   {}   \n",
      "89                   {}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                            ag_args_fit  \\\n",
      "0   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
      "85  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "86  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "87  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "88  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "89  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   features  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                      [NeuralNetTorch_r30_BAG_L2_2, NeuralNetTorch_r30_BAG_L2_0, NeuralNetTorch_r30_BAG_L2_1, NeuralNetFastAI_r134_BAG_L2_1, NeuralNetFastAI_r134_BAG_L2_0, NeuralNetFastAI_r134_BAG_L2_2]   \n",
      "1   [NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_0, NeuralNetTorch_r158_BAG_L1_0, NeuralNetTorch_r1_BAG_L1_2, NeuralNetFastAI_r187_BAG_L1_1, NeuralNetFastAI_r145_BAG_L1_2, NeuralNetFastAI_r138_BAG_L1_2, NeuralNetTorch_r158_BAG_L1_2, NeuralNetFastAI_r103_BAG_L1_1, NeuralNetFastAI_r194_BAG_L1_0, NeuralNetFastAI_BAG_L1_0, ParentAnsweringSurvey, NeuralNetTorch_r19_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_1, Discussion, NeuralNetTorch_r79_BAG_L1_1, NeuralNetFastAI_r88_BAG_L1_0, StageID, NeuralNetFastAI_r69_BAG_L1_1, AnnouncementsView, NeuralNetTorch_r76_BAG_L1_...   \n",
      "2   [NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_0, NeuralNetTorch_r158_BAG_L1_0, NeuralNetTorch_r1_BAG_L1_2, NeuralNetFastAI_r187_BAG_L1_1, NeuralNetFastAI_r145_BAG_L1_2, NeuralNetFastAI_r138_BAG_L1_2, NeuralNetTorch_r158_BAG_L1_2, NeuralNetFastAI_r103_BAG_L1_1, NeuralNetFastAI_r194_BAG_L1_0, NeuralNetFastAI_BAG_L1_0, ParentAnsweringSurvey, NeuralNetTorch_r19_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_1, Discussion, NeuralNetTorch_r79_BAG_L1_1, NeuralNetFastAI_r88_BAG_L1_0, StageID, NeuralNetFastAI_r69_BAG_L1_1, AnnouncementsView, NeuralNetTorch_r76_BAG_L1_...   \n",
      "3   [NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_0, NeuralNetTorch_r158_BAG_L1_0, NeuralNetTorch_r1_BAG_L1_2, NeuralNetFastAI_r187_BAG_L1_1, NeuralNetFastAI_r145_BAG_L1_2, NeuralNetFastAI_r138_BAG_L1_2, NeuralNetTorch_r158_BAG_L1_2, NeuralNetFastAI_r103_BAG_L1_1, NeuralNetFastAI_r194_BAG_L1_0, NeuralNetFastAI_BAG_L1_0, ParentAnsweringSurvey, NeuralNetTorch_r19_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_1, Discussion, NeuralNetTorch_r79_BAG_L1_1, NeuralNetFastAI_r88_BAG_L1_0, StageID, NeuralNetFastAI_r69_BAG_L1_1, AnnouncementsView, NeuralNetTorch_r76_BAG_L1_...   \n",
      "4   [NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_0, NeuralNetTorch_r158_BAG_L1_0, NeuralNetTorch_r1_BAG_L1_2, NeuralNetFastAI_r187_BAG_L1_1, NeuralNetFastAI_r145_BAG_L1_2, NeuralNetFastAI_r138_BAG_L1_2, NeuralNetTorch_r158_BAG_L1_2, NeuralNetFastAI_r103_BAG_L1_1, NeuralNetFastAI_r194_BAG_L1_0, NeuralNetFastAI_BAG_L1_0, ParentAnsweringSurvey, NeuralNetTorch_r19_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_1, Discussion, NeuralNetTorch_r79_BAG_L1_1, NeuralNetFastAI_r88_BAG_L1_0, StageID, NeuralNetFastAI_r69_BAG_L1_1, AnnouncementsView, NeuralNetTorch_r76_BAG_L1_...   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
      "85                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "86                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "87                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "88                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "89                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "\n",
      "    compile_time  \\\n",
      "0           None   \n",
      "1           None   \n",
      "2           None   \n",
      "3           None   \n",
      "4           None   \n",
      "..           ...   \n",
      "85          None   \n",
      "86          None   \n",
      "87          None   \n",
      "88          None   \n",
      "89          None   \n",
      "\n",
      "                                                                                                                                                                                                               child_hyperparameters  \\\n",
      "0                                                                                                                                                                                   {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
      "1       {'layers': [800, 400], 'emb_drop': 0.006251885504130949, 'ps': 0.2677080696008348, 'bs': 2048, 'lr': 0.01329622020483052, 'epochs': 47, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "2   {'layers': [200, 100, 50], 'emb_drop': 0.5074958658302495, 'ps': 0.34814978753283593, 'bs': 1024, 'lr': 0.026342427824862867, 'epochs': 42, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "3           {'layers': [400], 'emb_drop': 0.22771721361129746, 'ps': 0.3734259772256502, 'bs': 1024, 'lr': 0.0005383511954451698, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "4      {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "..                                                                                                                                                                                                                               ...   \n",
      "85        {'layers': [800, 400], 'emb_drop': 0.5411770367537934, 'ps': 0.23782946566604385, 'bs': 256, 'lr': 0.01519848858318159, 'epochs': 43, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "86       {'layers': [400, 200], 'emb_drop': 0.6343202884164582, 'ps': 0.48362560779595565, 'bs': 2048, 'lr': 0.08479209380262258, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "87    {'layers': [400, 200, 100], 'emb_drop': 0.3171659718142149, 'ps': 0.5909644730871169, 'bs': 128, 'lr': 0.03087210106068273, 'epochs': 20, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "88     {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "89   {'layers': [400, 200, 100], 'emb_drop': 0.5117456464220826, 'ps': 0.2747013981281539, 'bs': 256, 'lr': 0.007212882302137526, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "\n",
      "           child_hyperparameters_fit  \\\n",
      "0               {'ensemble_size': 4}   \n",
      "1    {'epochs': 47, 'best_epoch': 6}   \n",
      "2    {'epochs': 42, 'best_epoch': 4}   \n",
      "3    {'epochs': 38, 'best_epoch': 8}   \n",
      "4    {'epochs': 38, 'best_epoch': 7}   \n",
      "..                               ...   \n",
      "85  {'epochs': 43, 'best_epoch': 14}   \n",
      "86   {'epochs': 21, 'best_epoch': 9}   \n",
      "87   {'epochs': 20, 'best_epoch': 7}   \n",
      "88  {'epochs': 38, 'best_epoch': 16}   \n",
      "89   {'epochs': 21, 'best_epoch': 9}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                              child_ag_args_fit  \\\n",
      "0                                           {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
      "85  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "86  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "87  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "88  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "89  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ancestors  \\\n",
      "0   [NeuralNetFastAI_r65_BAG_L1, NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, Neu...   \n",
      "1   [NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r89_BAG_L1, Neur...   \n",
      "2   [NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r89_BAG_L1, Neur...   \n",
      "3   [NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r89_BAG_L1, Neur...   \n",
      "4   [NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r89_BAG_L1, Neur...   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
      "85                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "86                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "87                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "88                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "89                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                descendants  \n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [WeightedEnsemble_L3]  \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...  \n",
      "85  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "86  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "87  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "88  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "89  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "\n",
      "[90 rows x 32 columns]\n",
      "Execution time (min): 59.290682995319365\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"XAPI\"\n",
    "DATA_PATH = \"xapi.csv\"\n",
    "TARGET = \"Class\"\n",
    "KFOLD = 10  # Number of folds for cross-validation\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# Remove spaces in column names (if any)\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "# Create a DataFrame including features and target\n",
    "df_selected = X.copy()\n",
    "df_selected[TARGET] = y\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "gpu_available = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "validation_type = 'kfold'\n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "# Define output directory\n",
    "path = f\"GPU_{gpu_available}_{FILENAME}_DL_VALIDATION_{validation_type}\"\n",
    "# If the directory already exists, delete it before creating a new one\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)  # Remove previous results\n",
    "#os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Create AutoGluon predictor\n",
    "predictor = TabularPredictor(\n",
    "    label=TARGET, \n",
    "    path=path, \n",
    "    problem_type=\"multiclass\",\n",
    ")\n",
    "\n",
    "# Fit models using AutoGluon with 10-fold bagging\n",
    "if gpu_available:\n",
    "    predictor.fit(\n",
    "        df_selected,\n",
    "        num_bag_folds=KFOLD,\n",
    "        verbosity=2,\n",
    "        num_gpus=1,\n",
    "        excluded_model_types=['RF', 'KNN', 'GBM', 'XGB', 'CAT', 'XT', 'LR'],\n",
    "        presets=\"best_quality\"\n",
    "    )\n",
    "else:\n",
    "    predictor.fit(\n",
    "        df_selected,\n",
    "        num_bag_folds=KFOLD,\n",
    "        verbosity=2,\n",
    "        excluded_model_types=['RF', 'KNN', 'GBM', 'XGB', 'CAT', 'XT', 'LR'],\n",
    "        presets=\"best_quality\"\n",
    "    )\n",
    "\n",
    "####\n",
    "# (A) Retrieve Out-Of-Fold (OOF) predictions\n",
    "####\n",
    "# This DataFrame contains predictions made for each instance when it was in the validation set of a given fold\n",
    "oof_pred = predictor.get_oof_pred()\n",
    "\n",
    "# Retrieve true labels corresponding to OOF predictions\n",
    "y_true_oof = df_selected.loc[oof_pred.index, TARGET]\n",
    "\n",
    "# Compute OOF metrics\n",
    "accuracy_oof = accuracy_score(y_true_oof, oof_pred)\n",
    "precision_oof = precision_score(y_true_oof, oof_pred, average='weighted')\n",
    "recall_oof = recall_score(y_true_oof, oof_pred, average='weighted')\n",
    "f1_oof = f1_score(y_true_oof, oof_pred, average='weighted')\n",
    "\n",
    "# For multi-class ROC-AUC:\n",
    "# predictor.get_oof_pred_proba() -> Then compute roc_auc_score\n",
    "proba_oof = predictor.get_oof_pred_proba()\n",
    "one_hot_true = pd.get_dummies(y_true_oof, drop_first=False)\n",
    "roc_auc_oof = roc_auc_score(one_hot_true, proba_oof, average='weighted', multi_class='ovr')\n",
    "# (B) Summary of cross-validation metrics\n",
    "cv_scores = predictor.leaderboard(extra_info=True)\n",
    "\n",
    "# Store OOF metrics in a DataFrame\n",
    "df_oof_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy (OOF)', 'Precision (OOF)', 'Recall (OOF)', 'F1 Score (OOF)', 'ROC AUC (OOF)'],\n",
    "    'Score': [accuracy_oof, precision_oof, recall_oof, f1_oof, roc_auc_oof]\n",
    "})\n",
    "\n",
    "####\n",
    "# (C) Evaluate model on the full training dataset (not a true test set)\n",
    "####\n",
    "y_pred_final = predictor.predict(df_selected)\n",
    "y_prob_final = predictor.predict_proba(df_selected)\n",
    "\n",
    "accuracy_final = accuracy_score(df_selected[TARGET], y_pred_final)\n",
    "precision_final = precision_score(df_selected[TARGET], y_pred_final, average='weighted')\n",
    "recall_final = recall_score(df_selected[TARGET], y_pred_final, average='weighted')\n",
    "f1_final = f1_score(df_selected[TARGET], y_pred_final, average='weighted')\n",
    "\n",
    "# For multi-class ROC-AUC:\n",
    "roc_auc_final = roc_auc_score(pd.get_dummies(df_selected[TARGET]), \n",
    "                                y_prob_final, \n",
    "                                average='weighted', \n",
    "                                multi_class='ovr')\n",
    "\n",
    "# Store final evaluation metrics in a DataFrame\n",
    "df_final_metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy (Final)', 'Precision (Final)', 'Recall (Final)', 'F1 Score (Final)', 'ROC AUC (Final)'],\n",
    "    'Score': [accuracy_final, precision_final, recall_final, f1_final, roc_auc_final]\n",
    "})\n",
    "\n",
    "# Save results to CSV files\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "\n",
    "filename_oof = f\"GPU_{gpu_available}_{FILENAME}_OOF_RESULTS_{validation_type}_{execution_time_minutes:.2f}.csv\"\n",
    "filename_final = f\"GPU_{gpu_available}_{FILENAME}_FINAL_RESULTS_{validation_type}_{execution_time_minutes:.2f}.csv\"\n",
    "\n",
    "df_oof_metrics.to_csv(filename_oof, index=False)\n",
    "df_final_metrics.to_csv(filename_final, index=False)\n",
    "\n",
    "print(\"OOF Metrics saved to:\", filename_oof)\n",
    "print(\"Final Metrics saved to:\", filename_final)\n",
    "print(\"CV Scores summary:\", cv_scores)\n",
    "print(\"Execution time (min):\", execution_time_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: ['NeuralNetFastAI_BAG_L1', 'NeuralNetTorch_BAG_L1', 'NeuralNetTorch_r79_BAG_L1', 'NeuralNetFastAI_r191_BAG_L1', 'NeuralNetTorch_r22_BAG_L1', 'NeuralNetFastAI_r102_BAG_L1', 'NeuralNetFastAI_r145_BAG_L1', 'NeuralNetTorch_r30_BAG_L1', 'NeuralNetTorch_r86_BAG_L1', 'NeuralNetFastAI_r11_BAG_L1', 'NeuralNetFastAI_r103_BAG_L1', 'NeuralNetTorch_r14_BAG_L1', 'NeuralNetFastAI_r143_BAG_L1', 'NeuralNetFastAI_r156_BAG_L1', 'NeuralNetFastAI_r95_BAG_L1', 'NeuralNetTorch_r41_BAG_L1', 'NeuralNetTorch_r158_BAG_L1', 'NeuralNetFastAI_r37_BAG_L1', 'NeuralNetTorch_r197_BAG_L1', 'NeuralNetFastAI_r134_BAG_L1', 'NeuralNetTorch_r143_BAG_L1', 'NeuralNetFastAI_r111_BAG_L1', 'NeuralNetTorch_r31_BAG_L1', 'NeuralNetFastAI_r65_BAG_L1', 'NeuralNetFastAI_r88_BAG_L1', 'NeuralNetTorch_r87_BAG_L1', 'NeuralNetTorch_r71_BAG_L1', 'NeuralNetTorch_r185_BAG_L1', 'NeuralNetFastAI_r160_BAG_L1', 'NeuralNetFastAI_r69_BAG_L1', 'NeuralNetFastAI_r138_BAG_L1', 'NeuralNetFastAI_r172_BAG_L1', 'NeuralNetTorch_r76_BAG_L1', 'NeuralNetTorch_r121_BAG_L1', 'NeuralNetFastAI_r127_BAG_L1', 'NeuralNetFastAI_r194_BAG_L1', 'NeuralNetTorch_r135_BAG_L1', 'NeuralNetFastAI_r4_BAG_L1', 'NeuralNetTorch_r36_BAG_L1', 'NeuralNetFastAI_r100_BAG_L1', 'NeuralNetFastAI_r187_BAG_L1', 'NeuralNetTorch_r19_BAG_L1', 'NeuralNetTorch_r1_BAG_L1', 'NeuralNetTorch_r89_BAG_L1', 'WeightedEnsemble_L2', 'NeuralNetFastAI_BAG_L2', 'NeuralNetTorch_BAG_L2', 'NeuralNetTorch_r79_BAG_L2', 'NeuralNetFastAI_r191_BAG_L2', 'NeuralNetTorch_r22_BAG_L2', 'NeuralNetFastAI_r102_BAG_L2', 'NeuralNetFastAI_r145_BAG_L2', 'NeuralNetTorch_r30_BAG_L2', 'NeuralNetTorch_r86_BAG_L2', 'NeuralNetFastAI_r11_BAG_L2', 'NeuralNetFastAI_r103_BAG_L2', 'NeuralNetTorch_r14_BAG_L2', 'NeuralNetFastAI_r143_BAG_L2', 'NeuralNetFastAI_r156_BAG_L2', 'NeuralNetFastAI_r95_BAG_L2', 'NeuralNetTorch_r41_BAG_L2', 'NeuralNetTorch_r158_BAG_L2', 'NeuralNetFastAI_r37_BAG_L2', 'NeuralNetTorch_r197_BAG_L2', 'NeuralNetFastAI_r134_BAG_L2', 'NeuralNetTorch_r143_BAG_L2', 'NeuralNetFastAI_r111_BAG_L2', 'NeuralNetTorch_r31_BAG_L2', 'NeuralNetFastAI_r65_BAG_L2', 'NeuralNetFastAI_r88_BAG_L2', 'NeuralNetTorch_r87_BAG_L2', 'NeuralNetTorch_r71_BAG_L2', 'NeuralNetTorch_r185_BAG_L2', 'NeuralNetFastAI_r160_BAG_L2', 'NeuralNetFastAI_r69_BAG_L2', 'NeuralNetFastAI_r138_BAG_L2', 'NeuralNetFastAI_r172_BAG_L2', 'NeuralNetTorch_r76_BAG_L2', 'NeuralNetTorch_r121_BAG_L2', 'NeuralNetFastAI_r127_BAG_L2', 'NeuralNetFastAI_r194_BAG_L2', 'NeuralNetTorch_r135_BAG_L2', 'NeuralNetFastAI_r4_BAG_L2', 'NeuralNetTorch_r36_BAG_L2', 'NeuralNetFastAI_r100_BAG_L2', 'NeuralNetFastAI_r187_BAG_L2', 'NeuralNetTorch_r19_BAG_L2', 'NeuralNetTorch_r1_BAG_L2', 'NeuralNetTorch_r89_BAG_L2', 'WeightedEnsemble_L3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAL\\AppData\\Local\\Temp\\ipykernel_600\\2533287609.py:17: DeprecationWarning: `get_model_names` has been deprecated and will be removed in version 1.2. Please use `model_names` instead. This will raise an error in the future!\n",
      "  model_names = predictor.get_model_names()\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# MODEL INSPECTION PART\n",
    "# ==========================\n",
    "\n",
    "# This script retrieves information about trained AutoGluon models, including:\n",
    "# Listing all trained models.\n",
    "# Extracting hyperparameters from a specific model.\n",
    "# Getting detailed training information.\n",
    "# Saving hyperparameters to a JSON file.\n",
    "# Displaying a full model summary.\n",
    "\n",
    "# ==========================\n",
    "# List all trained models\n",
    "# ==========================\n",
    "# AutoGluon trains multiple models (e.g., stacked, bagged, ensembles).\n",
    "# This command lists all trained models in the predictor.\n",
    "model_names = predictor.get_model_names()\n",
    "print(\"Available Models:\", model_names)\n",
    "# Example output: \n",
    "# ['WeightedEnsemble_L2', \n",
    "# 'LightGBMXT_BAG_L1', \n",
    "# 'LightGBM_BAG_L1', \n",
    "# 'NeuralNetMXNet_BAG_L1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAL\\AppData\\Local\\Temp\\ipykernel_600\\640000609.py:4: DeprecationWarning: `get_model_best` has been deprecated and will be removed in version 1.2. Please use `model_best` instead. This will raise an error in the future!\n",
      "  best_model_name = predictor.get_model_best()  # Get the name of the best-performing model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: WeightedEnsemble_L3\n",
      "Hyperparameters of the best model: {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Get hyperparameters of a specific model\n",
    "# ==========================\n",
    "best_model_name = predictor.get_model_best()  # Get the name of the best-performing model\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "# Retrieve hyperparameters of the best-performing model\n",
    "model_info = predictor.info()\n",
    "best_model_hyperparameters = model_info['model_info'][best_model_name]['hyperparameters']\n",
    "print(f\"Hyperparameters of the best model: {best_model_hyperparameters}\")\n",
    "#Example output: Hyperparameters of the best model:\n",
    "# {'use_orig_features': False, \n",
    "# 'max_base_models': 25, \n",
    "# 'max_base_models_per_type': 5, \n",
    "# 'save_bag_folds': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training details of WeightedEnsemble_L3:\n",
      "{'name': 'WeightedEnsemble_L3', 'model_type': 'WeightedEnsembleModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.07345986366271973, 'num_classes': 3, 'quantile_levels': None, 'predict_time': 0.0, 'val_score': 0.8854166666666666, 'hyperparameters': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'hyperparameters_fit': {}, 'hyperparameters_nondefault': ['save_bag_folds'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 6, 'features': ['NeuralNetTorch_r30_BAG_L2_2', 'NeuralNetTorch_r30_BAG_L2_0', 'NeuralNetTorch_r30_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_0', 'NeuralNetFastAI_r134_BAG_L2_2'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x0000027E26141310>, 'memory_size': 26017, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'bagged_info': {'child_model_type': 'GreedyWeightedEnsembleModel', 'num_child_models': 1, 'child_model_names': ['S1F1'], '_n_repeats': 1, '_k_per_n_repeat': [1], '_random_state': 3, 'low_memory': False, 'bagged_mode': False, 'max_memory_size': 26017, 'min_memory_size': 26017, 'child_hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'child_hyperparameters_fit': {'ensemble_size': 4}, 'child_ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}}, 'stacker_info': {'num_base_models': 2, 'base_model_names': ['NeuralNetTorch_r30_BAG_L2', 'NeuralNetFastAI_r134_BAG_L2']}, 'children_info': {'S1F1': {'name': 'S1F1', 'model_type': 'GreedyWeightedEnsembleModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.07345986366271973, 'num_classes': 3, 'quantile_levels': None, 'predict_time': None, 'val_score': None, 'hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'hyperparameters_fit': {'ensemble_size': 4}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 6, 'features': ['NeuralNetTorch_r30_BAG_L2_0', 'NeuralNetTorch_r30_BAG_L2_1', 'NeuralNetTorch_r30_BAG_L2_2', 'NeuralNetFastAI_r134_BAG_L2_0', 'NeuralNetFastAI_r134_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_2'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x0000027E25C68890>, 'memory_size': 7343, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'model_weights': {'NeuralNetTorch_r30_BAG_L2': 0.25, 'NeuralNetFastAI_r134_BAG_L2': 0.75}}}}\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Get model-specific training details\n",
    "# ==========================\n",
    "# Retrieve additional information about the model (training time, memory usage, etc.)\n",
    "model_name = best_model_name  # or specify any other model name\n",
    "model_info = predictor.info()\n",
    "training_details = model_info['model_info'][model_name]\n",
    "print(f\"Training details of {model_name}:\")\n",
    "print(training_details)\n",
    "\n",
    "# Example output:\n",
    "# {'name': 'WeightedEnsemble_L3', 'model_type': 'WeightedEnsembleModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.07663822174072266, 'num_classes': 3, 'quantile_levels': None, 'predict_time': 0.0010030269622802734, 'val_score': 0.8854166666666666, 'hyperparameters': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'hyperparameters_fit': {}, 'hyperparameters_nondefault': ['save_bag_folds'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 6, 'features': ['NeuralNetTorch_r30_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_2', 'NeuralNetTorch_r30_BAG_L2_2', 'NeuralNetFastAI_r134_BAG_L2_1', 'NeuralNetTorch_r30_BAG_L2_0', 'NeuralNetFastAI_r134_BAG_L2_0'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x00000199481A5A10>, 'memory_size': 26017, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'bagged_info': {'child_model_type': 'GreedyWeightedEnsembleModel', 'num_child_models': 1, 'child_model_names': ['S1F1'], '_n_repeats': 1, '_k_per_n_repeat': [1], '_random_state': 3, 'low_memory': False, 'bagged_mode': False, 'max_memory_size': 26017, 'min_memory_size': 26017, 'child_hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'child_hyperparameters_fit': {'ensemble_size': 4}, 'child_ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}}, 'stacker_info': {'num_base_models': 2, 'base_model_names': ['NeuralNetTorch_r30_BAG_L2', 'NeuralNetFastAI_r134_BAG_L2']}, 'children_info': {'S1F1': {'name': 'S1F1', 'model_type': 'GreedyWeightedEnsembleModel', 'problem_type': 'multiclass', 'eval_metric': 'accuracy', 'stopping_metric': 'accuracy', 'fit_time': 0.07663822174072266, 'num_classes': 3, 'quantile_levels': None, 'predict_time': None, 'val_score': None, 'hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'hyperparameters_fit': {'ensemble_size': 4}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 6, 'features': ['NeuralNetTorch_r30_BAG_L2_0', 'NeuralNetTorch_r30_BAG_L2_1', 'NeuralNetTorch_r30_BAG_L2_2', 'NeuralNetFastAI_r134_BAG_L2_0', 'NeuralNetFastAI_r134_BAG_L2_1', 'NeuralNetFastAI_r134_BAG_L2_2'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x00000199481A7690>, 'memory_size': 7343, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'model_weights': {'NeuralNetTorch_r30_BAG_L2': 0.25, 'NeuralNetFastAI_r134_BAG_L2': 0.75}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model summary:\n",
      "                          model  score_val eval_metric  pred_time_val  \\\n",
      "0           WeightedEnsemble_L3   0.885417    accuracy       3.295865   \n",
      "1   NeuralNetFastAI_r134_BAG_L2   0.881250    accuracy       3.119995   \n",
      "2   NeuralNetFastAI_r187_BAG_L2   0.879167    accuracy       3.132973   \n",
      "3    NeuralNetFastAI_r65_BAG_L2   0.877083    accuracy       3.126476   \n",
      "4   NeuralNetFastAI_r100_BAG_L2   0.877083    accuracy       3.128721   \n",
      "..                          ...        ...         ...            ...   \n",
      "85  NeuralNetFastAI_r191_BAG_L1   0.789583    accuracy       0.075795   \n",
      "86  NeuralNetFastAI_r111_BAG_L1   0.785417    accuracy       0.094508   \n",
      "87  NeuralNetFastAI_r160_BAG_L1   0.783333    accuracy       0.078439   \n",
      "88  NeuralNetFastAI_r100_BAG_L1   0.779167    accuracy       0.094456   \n",
      "89  NeuralNetFastAI_r194_BAG_L1   0.775000    accuracy       0.078996   \n",
      "\n",
      "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   1459.200022                0.000000           0.073460            3   \n",
      "1   1418.518621                0.091960          33.040642            2   \n",
      "2   1414.599989                0.104939          29.122010            2   \n",
      "3   1413.897557                0.098441          28.419578            2   \n",
      "4   1421.082728                0.100686          35.604748            2   \n",
      "..          ...                     ...                ...          ...   \n",
      "85    18.835353                0.075795          18.835353            1   \n",
      "86    25.075900                0.094508          25.075900            1   \n",
      "87    18.860267                0.078439          18.860267            1   \n",
      "88    35.602620                0.094456          35.602620            1   \n",
      "89    17.569243                0.078996          17.569243            1   \n",
      "\n",
      "    can_infer  fit_order  ...  \\\n",
      "0        True         90  ...   \n",
      "1        True         65  ...   \n",
      "2        True         86  ...   \n",
      "3        True         69  ...   \n",
      "4        True         85  ...   \n",
      "..        ...        ...  ...   \n",
      "85       True          4  ...   \n",
      "86       True         22  ...   \n",
      "87       True         29  ...   \n",
      "88       True         40  ...   \n",
      "89       True         36  ...   \n",
      "\n",
      "                                                                                               hyperparameters  \\\n",
      "0   {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "1    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "2    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "3    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "4    {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "..                                                                                                         ...   \n",
      "85   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "86   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "87   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "88   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "89   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
      "\n",
      "    hyperparameters_fit  \\\n",
      "0                    {}   \n",
      "1                    {}   \n",
      "2                    {}   \n",
      "3                    {}   \n",
      "4                    {}   \n",
      "..                  ...   \n",
      "85                   {}   \n",
      "86                   {}   \n",
      "87                   {}   \n",
      "88                   {}   \n",
      "89                   {}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                            ag_args_fit  \\\n",
      "0   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
      "85  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "86  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "87  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "88  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "89  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   features  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                      [NeuralNetTorch_r30_BAG_L2_2, NeuralNetTorch_r30_BAG_L2_0, NeuralNetTorch_r30_BAG_L2_1, NeuralNetFastAI_r134_BAG_L2_1, NeuralNetFastAI_r134_BAG_L2_0, NeuralNetFastAI_r134_BAG_L2_2]   \n",
      "1   [NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_0, NeuralNetTorch_r158_BAG_L1_0, NeuralNetTorch_r1_BAG_L1_2, NeuralNetFastAI_r187_BAG_L1_1, NeuralNetFastAI_r145_BAG_L1_2, NeuralNetFastAI_r138_BAG_L1_2, NeuralNetTorch_r158_BAG_L1_2, NeuralNetFastAI_r103_BAG_L1_1, NeuralNetFastAI_r194_BAG_L1_0, NeuralNetFastAI_BAG_L1_0, ParentAnsweringSurvey, NeuralNetTorch_r19_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_1, Discussion, NeuralNetTorch_r79_BAG_L1_1, NeuralNetFastAI_r88_BAG_L1_0, StageID, NeuralNetFastAI_r69_BAG_L1_1, AnnouncementsView, NeuralNetTorch_r76_BAG_L1_...   \n",
      "2   [NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_0, NeuralNetTorch_r158_BAG_L1_0, NeuralNetTorch_r1_BAG_L1_2, NeuralNetFastAI_r187_BAG_L1_1, NeuralNetFastAI_r145_BAG_L1_2, NeuralNetFastAI_r138_BAG_L1_2, NeuralNetTorch_r158_BAG_L1_2, NeuralNetFastAI_r103_BAG_L1_1, NeuralNetFastAI_r194_BAG_L1_0, NeuralNetFastAI_BAG_L1_0, ParentAnsweringSurvey, NeuralNetTorch_r19_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_1, Discussion, NeuralNetTorch_r79_BAG_L1_1, NeuralNetFastAI_r88_BAG_L1_0, StageID, NeuralNetFastAI_r69_BAG_L1_1, AnnouncementsView, NeuralNetTorch_r76_BAG_L1_...   \n",
      "3   [NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_0, NeuralNetTorch_r158_BAG_L1_0, NeuralNetTorch_r1_BAG_L1_2, NeuralNetFastAI_r187_BAG_L1_1, NeuralNetFastAI_r145_BAG_L1_2, NeuralNetFastAI_r138_BAG_L1_2, NeuralNetTorch_r158_BAG_L1_2, NeuralNetFastAI_r103_BAG_L1_1, NeuralNetFastAI_r194_BAG_L1_0, NeuralNetFastAI_BAG_L1_0, ParentAnsweringSurvey, NeuralNetTorch_r19_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_1, Discussion, NeuralNetTorch_r79_BAG_L1_1, NeuralNetFastAI_r88_BAG_L1_0, StageID, NeuralNetFastAI_r69_BAG_L1_1, AnnouncementsView, NeuralNetTorch_r76_BAG_L1_...   \n",
      "4   [NeuralNetTorch_r143_BAG_L1_1, NeuralNetFastAI_r143_BAG_L1_0, NeuralNetTorch_r79_BAG_L1_0, NeuralNetTorch_r158_BAG_L1_0, NeuralNetTorch_r1_BAG_L1_2, NeuralNetFastAI_r187_BAG_L1_1, NeuralNetFastAI_r145_BAG_L1_2, NeuralNetFastAI_r138_BAG_L1_2, NeuralNetTorch_r158_BAG_L1_2, NeuralNetFastAI_r103_BAG_L1_1, NeuralNetFastAI_r194_BAG_L1_0, NeuralNetFastAI_BAG_L1_0, ParentAnsweringSurvey, NeuralNetTorch_r19_BAG_L1_2, NeuralNetTorch_r76_BAG_L1_1, Discussion, NeuralNetTorch_r79_BAG_L1_1, NeuralNetFastAI_r88_BAG_L1_0, StageID, NeuralNetFastAI_r69_BAG_L1_1, AnnouncementsView, NeuralNetTorch_r76_BAG_L1_...   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
      "85                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "86                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "87                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "88                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "89                                                                                                                                                                                                                                                                                                                                                                                           [Relation, PlaceofBirth, StageID, SectionID, ParentAnsweringSurvey, AnnouncementsView, GradeID, VisITedResources, gender, Discussion, NationalITy, Semester, Topic, ParentschoolSatisfaction, raisedhands, StudentAbsenceDays]   \n",
      "\n",
      "    compile_time  \\\n",
      "0           None   \n",
      "1           None   \n",
      "2           None   \n",
      "3           None   \n",
      "4           None   \n",
      "..           ...   \n",
      "85          None   \n",
      "86          None   \n",
      "87          None   \n",
      "88          None   \n",
      "89          None   \n",
      "\n",
      "                                                                                                                                                                                                               child_hyperparameters  \\\n",
      "0                                                                                                                                                                                   {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
      "1       {'layers': [800, 400], 'emb_drop': 0.006251885504130949, 'ps': 0.2677080696008348, 'bs': 2048, 'lr': 0.01329622020483052, 'epochs': 47, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "2   {'layers': [200, 100, 50], 'emb_drop': 0.5074958658302495, 'ps': 0.34814978753283593, 'bs': 1024, 'lr': 0.026342427824862867, 'epochs': 42, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "3           {'layers': [400], 'emb_drop': 0.22771721361129746, 'ps': 0.3734259772256502, 'bs': 1024, 'lr': 0.0005383511954451698, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "4      {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "..                                                                                                                                                                                                                               ...   \n",
      "85        {'layers': [800, 400], 'emb_drop': 0.5411770367537934, 'ps': 0.23782946566604385, 'bs': 256, 'lr': 0.01519848858318159, 'epochs': 43, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "86       {'layers': [400, 200], 'emb_drop': 0.6343202884164582, 'ps': 0.48362560779595565, 'bs': 2048, 'lr': 0.08479209380262258, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "87    {'layers': [400, 200, 100], 'emb_drop': 0.3171659718142149, 'ps': 0.5909644730871169, 'bs': 128, 'lr': 0.03087210106068273, 'epochs': 20, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "88     {'layers': [800, 400], 'emb_drop': 0.6960805527533755, 'ps': 0.20495582200836318, 'bs': 2048, 'lr': 0.0007278526871749883, 'epochs': 38, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "89   {'layers': [400, 200, 100], 'emb_drop': 0.5117456464220826, 'ps': 0.2747013981281539, 'bs': 256, 'lr': 0.007212882302137526, 'epochs': 21, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}   \n",
      "\n",
      "           child_hyperparameters_fit  \\\n",
      "0               {'ensemble_size': 4}   \n",
      "1    {'epochs': 47, 'best_epoch': 6}   \n",
      "2    {'epochs': 42, 'best_epoch': 4}   \n",
      "3    {'epochs': 38, 'best_epoch': 8}   \n",
      "4    {'epochs': 38, 'best_epoch': 7}   \n",
      "..                               ...   \n",
      "85  {'epochs': 43, 'best_epoch': 14}   \n",
      "86   {'epochs': 21, 'best_epoch': 9}   \n",
      "87   {'epochs': 20, 'best_epoch': 7}   \n",
      "88  {'epochs': 38, 'best_epoch': 16}   \n",
      "89   {'epochs': 21, 'best_epoch': 9}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                              child_ag_args_fit  \\\n",
      "0                                           {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
      "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
      "85  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "86  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "87  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "88  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "89  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ancestors  \\\n",
      "0   [NeuralNetFastAI_r65_BAG_L1, NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, Neu...   \n",
      "1   [NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r89_BAG_L1, Neur...   \n",
      "2   [NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r89_BAG_L1, Neur...   \n",
      "3   [NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r89_BAG_L1, Neur...   \n",
      "4   [NeuralNetFastAI_r160_BAG_L1, NeuralNetTorch_r41_BAG_L1, NeuralNetFastAI_r191_BAG_L1, NeuralNetTorch_r30_BAG_L1, NeuralNetFastAI_r127_BAG_L1, NeuralNetFastAI_r143_BAG_L1, NeuralNetTorch_r158_BAG_L1, NeuralNetTorch_r76_BAG_L1, NeuralNetFastAI_r102_BAG_L1, NeuralNetTorch_r185_BAG_L1, NeuralNetFastAI_r103_BAG_L1, NeuralNetFastAI_r37_BAG_L1, NeuralNetFastAI_r100_BAG_L1, NeuralNetFastAI_r156_BAG_L1, NeuralNetFastAI_r95_BAG_L1, NeuralNetFastAI_r69_BAG_L1, NeuralNetFastAI_r11_BAG_L1, NeuralNetFastAI_r172_BAG_L1, NeuralNetTorch_r121_BAG_L1, NeuralNetTorch_r1_BAG_L1, NeuralNetTorch_r89_BAG_L1, Neur...   \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
      "85                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "86                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "87                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "88                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "89                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       []   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                descendants  \n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [WeightedEnsemble_L3]  \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        []  \n",
      "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...  \n",
      "85  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "86  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "87  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "88  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "89  [NeuralNetFastAI_r138_BAG_L2, NeuralNetTorch_r76_BAG_L2, NeuralNetFastAI_r69_BAG_L2, NeuralNetFastAI_r95_BAG_L2, NeuralNetFastAI_r100_BAG_L2, NeuralNetFastAI_r160_BAG_L2, NeuralNetTorch_r197_BAG_L2, NeuralNetFastAI_r143_BAG_L2, NeuralNetFastAI_r127_BAG_L2, NeuralNetTorch_r158_BAG_L2, NeuralNetTorch_r41_BAG_L2, NeuralNetFastAI_BAG_L2, NeuralNetFastAI_r194_BAG_L2, NeuralNetTorch_r36_BAG_L2, NeuralNetTorch_r121_BAG_L2, NeuralNetTorch_r87_BAG_L2, NeuralNetFastAI_r187_BAG_L2, NeuralNetTorch_r22_BAG_L2, NeuralNetTorch_r185_BAG_L2, NeuralNetFastAI_r111_BAG_L2, NeuralNetTorch_BAG_L2, NeuralNetTorc...  \n",
      "\n",
      "[90 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Retrieve full model summary\n",
    "# ==========================\n",
    "# Display a leaderboard with all trained models, including:\n",
    "# - Train time\n",
    "# - Validation accuracy\n",
    "# - Performance metrics\n",
    "summary = predictor.leaderboard(extra_info=True)\n",
    "print(\"Full model summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 16 features using 480 rows with 5 shuffle sets...\n",
      "\t1168.18s\t= Expected runtime (233.64s per shuffle set)\n",
      "\t402.62s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5</td>\n",
       "      <td>0.252186</td>\n",
       "      <td>0.187814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <td>0.082917</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>5</td>\n",
       "      <td>0.105082</td>\n",
       "      <td>0.060751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relation</th>\n",
       "      <td>0.082917</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5</td>\n",
       "      <td>0.096948</td>\n",
       "      <td>0.068885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raisedhands</th>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>5</td>\n",
       "      <td>0.105660</td>\n",
       "      <td>0.037673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VisITedResources</th>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>5</td>\n",
       "      <td>0.087523</td>\n",
       "      <td>0.039144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>5</td>\n",
       "      <td>0.079873</td>\n",
       "      <td>0.041794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>5</td>\n",
       "      <td>0.056942</td>\n",
       "      <td>0.032225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion</th>\n",
       "      <td>0.044167</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5</td>\n",
       "      <td>0.056070</td>\n",
       "      <td>0.032263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058297</td>\n",
       "      <td>0.029203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradeID</th>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>5</td>\n",
       "      <td>0.053810</td>\n",
       "      <td>0.033690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <td>0.040417</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>5</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.023098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NationalITy</th>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>0.031558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045350</td>\n",
       "      <td>0.023816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SectionID</th>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>5</td>\n",
       "      <td>0.034055</td>\n",
       "      <td>0.007612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Semester</th>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>0.007234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StageID</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014275</td>\n",
       "      <td>-0.001775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          importance    stddev   p_value  n  p99_high  \\\n",
       "StudentAbsenceDays          0.220000  0.015632  0.000003  5  0.252186   \n",
       "Topic                       0.082917  0.010765  0.000033  5  0.105082   \n",
       "Relation                    0.082917  0.006815  0.000005  5  0.096948   \n",
       "raisedhands                 0.071667  0.016510  0.000315  5  0.105660   \n",
       "VisITedResources            0.063333  0.011748  0.000136  5  0.087523   \n",
       "gender                      0.060833  0.009247  0.000062  5  0.079873   \n",
       "PlaceofBirth                0.044583  0.006002  0.000038  5  0.056942   \n",
       "Discussion                  0.044167  0.005781  0.000034  5  0.056070   \n",
       "ParentAnsweringSurvey       0.043750  0.007065  0.000079  5  0.058297   \n",
       "GradeID                     0.043750  0.004886  0.000018  5  0.053810   \n",
       "AnnouncementsView           0.040417  0.008411  0.000213  5  0.057735   \n",
       "NationalITy                 0.039583  0.003898  0.000011  5  0.047608   \n",
       "ParentschoolSatisfaction    0.034583  0.005229  0.000061  5  0.045350   \n",
       "SectionID                   0.020833  0.006421  0.000958  5  0.034055   \n",
       "Semester                    0.009583  0.001141  0.000024  5  0.011933   \n",
       "StageID                     0.006250  0.003898  0.011525  5  0.014275   \n",
       "\n",
       "                           p99_low  \n",
       "StudentAbsenceDays        0.187814  \n",
       "Topic                     0.060751  \n",
       "Relation                  0.068885  \n",
       "raisedhands               0.037673  \n",
       "VisITedResources          0.039144  \n",
       "gender                    0.041794  \n",
       "PlaceofBirth              0.032225  \n",
       "Discussion                0.032263  \n",
       "ParentAnsweringSurvey     0.029203  \n",
       "GradeID                   0.033690  \n",
       "AnnouncementsView         0.023098  \n",
       "NationalITy               0.031558  \n",
       "ParentschoolSatisfaction  0.023816  \n",
       "SectionID                 0.007612  \n",
       "Semester                  0.007234  \n",
       "StageID                  -0.001775  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(df_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
